==================================================
FINETUNING PARAMETERS:
base model: tiiuae/falcon-7b
--------------------------------------------------
train_split: [:20000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/falcon_fft_en-es10k_ebs256_linear_lr1e-5_20231205-15.51.50
--------------------------------------------------
learning_rate: 1e-05
lr_scheduler_type: linear
effective batch size: 256
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 16
  CUDA Devices: 0,1,2,3
max_steps: 10000
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 50
--------------------------------------------------
bf16: True
==================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 20000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 20000
})
False
False
Grad req: transformer.word_embeddings.weight
Grad req: transformer.h.0.self_attention.query_key_value.weight
Grad req: transformer.h.0.self_attention.dense.weight
Grad req: transformer.h.0.mlp.dense_h_to_4h.weight
Grad req: transformer.h.0.mlp.dense_4h_to_h.weight
Grad req: transformer.h.0.input_layernorm.weight
Grad req: transformer.h.0.input_layernorm.bias
Grad req: transformer.h.1.self_attention.query_key_value.weight
Grad req: transformer.h.1.self_attention.dense.weight
Grad req: transformer.h.1.mlp.dense_h_to_4h.weight
Grad req: transformer.h.1.mlp.dense_4h_to_h.weight
Grad req: transformer.h.1.input_layernorm.weight
Grad req: transformer.h.1.input_layernorm.bias
Grad req: transformer.h.2.self_attention.query_key_value.weight
Grad req: transformer.h.2.self_attention.dense.weight
Grad req: transformer.h.2.mlp.dense_h_to_4h.weight
Grad req: transformer.h.2.mlp.dense_4h_to_h.weight
Grad req: transformer.h.2.input_layernorm.weight
Grad req: transformer.h.2.input_layernorm.bias
Grad req: transformer.h.3.self_attention.query_key_value.weight
Grad req: transformer.h.3.self_attention.dense.weight
Grad req: transformer.h.3.mlp.dense_h_to_4h.weight
Grad req: transformer.h.3.mlp.dense_4h_to_h.weight
Grad req: transformer.h.3.input_layernorm.weight
Grad req: transformer.h.3.input_layernorm.bias
Grad req: transformer.h.4.self_attention.query_key_value.weight
Grad req: transformer.h.4.self_attention.dense.weight
Grad req: transformer.h.4.mlp.dense_h_to_4h.weight
Grad req: transformer.h.4.mlp.dense_4h_to_h.weight
Grad req: transformer.h.4.input_layernorm.weight
Grad req: transformer.h.4.input_layernorm.bias
Grad req: transformer.h.5.self_attention.query_key_value.weight
Grad req: transformer.h.5.self_attention.dense.weight
Grad req: transformer.h.5.mlp.dense_h_to_4h.weight
Grad req: transformer.h.5.mlp.dense_4h_to_h.weight
Grad req: transformer.h.5.input_layernorm.weight
Grad req: transformer.h.5.input_layernorm.bias
Grad req: transformer.h.6.self_attention.query_key_value.weight
Grad req: transformer.h.6.self_attention.dense.weight
Grad req: transformer.h.6.mlp.dense_h_to_4h.weight
Grad req: transformer.h.6.mlp.dense_4h_to_h.weight
Grad req: transformer.h.6.input_layernorm.weight
Grad req: transformer.h.6.input_layernorm.bias
Grad req: transformer.h.7.self_attention.query_key_value.weight
Grad req: transformer.h.7.self_attention.dense.weight
Grad req: transformer.h.7.mlp.dense_h_to_4h.weight
Grad req: transformer.h.7.mlp.dense_4h_to_h.weight
Grad req: transformer.h.7.input_layernorm.weight
Grad req: transformer.h.7.input_layernorm.bias
Grad req: transformer.h.8.self_attention.query_key_value.weight
Grad req: transformer.h.8.self_attention.dense.weight
Grad req: transformer.h.8.mlp.dense_h_to_4h.weight
Grad req: transformer.h.8.mlp.dense_4h_to_h.weight
Grad req: transformer.h.8.input_layernorm.weight
Grad req: transformer.h.8.input_layernorm.bias
Grad req: transformer.h.9.self_attention.query_key_value.weight
Grad req: transformer.h.9.self_attention.dense.weight
Grad req: transformer.h.9.mlp.dense_h_to_4h.weight
Grad req: transformer.h.9.mlp.dense_4h_to_h.weight
Grad req: transformer.h.9.input_layernorm.weight
Grad req: transformer.h.9.input_layernorm.bias
Grad req: transformer.h.10.self_attention.query_key_value.weight
Grad req: transformer.h.10.self_attention.dense.weight
Grad req: transformer.h.10.mlp.dense_h_to_4h.weight
Grad req: transformer.h.10.mlp.dense_4h_to_h.weight
Grad req: transformer.h.10.input_layernorm.weight
Grad req: transformer.h.10.input_layernorm.bias
Grad req: transformer.h.11.self_attention.query_key_value.weight
Grad req: transformer.h.11.self_attention.dense.weight
Grad req: transformer.h.11.mlp.dense_h_to_4h.weight
Grad req: transformer.h.11.mlp.dense_4h_to_h.weight
Grad req: transformer.h.11.input_layernorm.weight
Grad req: transformer.h.11.input_layernorm.bias
Grad req: transformer.h.12.self_attention.query_key_value.weight
Grad req: transformer.h.12.self_attention.dense.weight
Grad req: transformer.h.12.mlp.dense_h_to_4h.weight
Grad req: transformer.h.12.mlp.dense_4h_to_h.weight
Grad req: transformer.h.12.input_layernorm.weight
Grad req: transformer.h.12.input_layernorm.bias
Grad req: transformer.h.13.self_attention.query_key_value.weight
Grad req: transformer.h.13.self_attention.dense.weight
Grad req: transformer.h.13.mlp.dense_h_to_4h.weight
Grad req: transformer.h.13.mlp.dense_4h_to_h.weight
Grad req: transformer.h.13.input_layernorm.weight
Grad req: transformer.h.13.input_layernorm.bias
Grad req: transformer.h.14.self_attention.query_key_value.weight
Grad req: transformer.h.14.self_attention.dense.weight
Grad req: transformer.h.14.mlp.dense_h_to_4h.weight
Grad req: transformer.h.14.mlp.dense_4h_to_h.weight
Grad req: transformer.h.14.input_layernorm.weight
Grad req: transformer.h.14.input_layernorm.bias
Grad req: transformer.h.15.self_attention.query_key_value.weight
Grad req: transformer.h.15.self_attention.dense.weight
Grad req: transformer.h.15.mlp.dense_h_to_4h.weight
Grad req: transformer.h.15.mlp.dense_4h_to_h.weight
Grad req: transformer.h.15.input_layernorm.weight
Grad req: transformer.h.15.input_layernorm.bias
Grad req: transformer.h.16.self_attention.query_key_value.weight
Grad req: transformer.h.16.self_attention.dense.weight
Grad req: transformer.h.16.mlp.dense_h_to_4h.weight
Grad req: transformer.h.16.mlp.dense_4h_to_h.weight
Grad req: transformer.h.16.input_layernorm.weight
Grad req: transformer.h.16.input_layernorm.bias
Grad req: transformer.h.17.self_attention.query_key_value.weight
Grad req: transformer.h.17.self_attention.dense.weight
Grad req: transformer.h.17.mlp.dense_h_to_4h.weight
Grad req: transformer.h.17.mlp.dense_4h_to_h.weight
Grad req: transformer.h.17.input_layernorm.weight
Grad req: transformer.h.17.input_layernorm.bias
Grad req: transformer.h.18.self_attention.query_key_value.weight
Grad req: transformer.h.18.self_attention.dense.weight
Grad req: transformer.h.18.mlp.dense_h_to_4h.weight
Grad req: transformer.h.18.mlp.dense_4h_to_h.weight
Grad req: transformer.h.18.input_layernorm.weight
Grad req: transformer.h.18.input_layernorm.bias
Grad req: transformer.h.19.self_attention.query_key_value.weight
Grad req: transformer.h.19.self_attention.dense.weight
Grad req: transformer.h.19.mlp.dense_h_to_4h.weight
Grad req: transformer.h.19.mlp.dense_4h_to_h.weight
Grad req: transformer.h.19.input_layernorm.weight
Grad req: transformer.h.19.input_layernorm.bias
Grad req: transformer.h.20.self_attention.query_key_value.weight
Grad req: transformer.h.20.self_attention.dense.weight
Grad req: transformer.h.20.mlp.dense_h_to_4h.weight
Grad req: transformer.h.20.mlp.dense_4h_to_h.weight
Grad req: transformer.h.20.input_layernorm.weight
Grad req: transformer.h.20.input_layernorm.bias
Grad req: transformer.h.21.self_attention.query_key_value.weight
Grad req: transformer.h.21.self_attention.dense.weight
Grad req: transformer.h.21.mlp.dense_h_to_4h.weight
Grad req: transformer.h.21.mlp.dense_4h_to_h.weight
Grad req: transformer.h.21.input_layernorm.weight
Grad req: transformer.h.21.input_layernorm.bias
Grad req: transformer.h.22.self_attention.query_key_value.weight
Grad req: transformer.h.22.self_attention.dense.weight
Grad req: transformer.h.22.mlp.dense_h_to_4h.weight
Grad req: transformer.h.22.mlp.dense_4h_to_h.weight
Grad req: transformer.h.22.input_layernorm.weight
Grad req: transformer.h.22.input_layernorm.bias
Grad req: transformer.h.23.self_attention.query_key_value.weight
Grad req: transformer.h.23.self_attention.dense.weight
Grad req: transformer.h.23.mlp.dense_h_to_4h.weight
Grad req: transformer.h.23.mlp.dense_4h_to_h.weight
Grad req: transformer.h.23.input_layernorm.weight
Grad req: transformer.h.23.input_layernorm.bias
Grad req: transformer.h.24.self_attention.query_key_value.weight
Grad req: transformer.h.24.self_attention.dense.weight
Grad req: transformer.h.24.mlp.dense_h_to_4h.weight
Grad req: transformer.h.24.mlp.dense_4h_to_h.weight
Grad req: transformer.h.24.input_layernorm.weight
Grad req: transformer.h.24.input_layernorm.bias
Grad req: transformer.h.25.self_attention.query_key_value.weight
Grad req: transformer.h.25.self_attention.dense.weight
Grad req: transformer.h.25.mlp.dense_h_to_4h.weight
Grad req: transformer.h.25.mlp.dense_4h_to_h.weight
Grad req: transformer.h.25.input_layernorm.weight
Grad req: transformer.h.25.input_layernorm.bias
Grad req: transformer.h.26.self_attention.query_key_value.weight
Grad req: transformer.h.26.self_attention.dense.weight
Grad req: transformer.h.26.mlp.dense_h_to_4h.weight
Grad req: transformer.h.26.mlp.dense_4h_to_h.weight
Grad req: transformer.h.26.input_layernorm.weight
Grad req: transformer.h.26.input_layernorm.bias
Grad req: transformer.h.27.self_attention.query_key_value.weight
Grad req: transformer.h.27.self_attention.dense.weight
Grad req: transformer.h.27.mlp.dense_h_to_4h.weight
Grad req: transformer.h.27.mlp.dense_4h_to_h.weight
Grad req: transformer.h.27.input_layernorm.weight
Grad req: transformer.h.27.input_layernorm.bias
Grad req: transformer.h.28.self_attention.query_key_value.weight
Grad req: transformer.h.28.self_attention.dense.weight
Grad req: transformer.h.28.mlp.dense_h_to_4h.weight
Grad req: transformer.h.28.mlp.dense_4h_to_h.weight
Grad req: transformer.h.28.input_layernorm.weight
Grad req: transformer.h.28.input_layernorm.bias
Grad req: transformer.h.29.self_attention.query_key_value.weight
Grad req: transformer.h.29.self_attention.dense.weight
Grad req: transformer.h.29.mlp.dense_h_to_4h.weight
Grad req: transformer.h.29.mlp.dense_4h_to_h.weight
Grad req: transformer.h.29.input_layernorm.weight
Grad req: transformer.h.29.input_layernorm.bias
Grad req: transformer.h.30.self_attention.query_key_value.weight
Grad req: transformer.h.30.self_attention.dense.weight
Grad req: transformer.h.30.mlp.dense_h_to_4h.weight
Grad req: transformer.h.30.mlp.dense_4h_to_h.weight
Grad req: transformer.h.30.input_layernorm.weight
Grad req: transformer.h.30.input_layernorm.bias
Grad req: transformer.h.31.self_attention.query_key_value.weight
Grad req: transformer.h.31.self_attention.dense.weight
Grad req: transformer.h.31.mlp.dense_h_to_4h.weight
Grad req: transformer.h.31.mlp.dense_4h_to_h.weight
Grad req: transformer.h.31.input_layernorm.weight
Grad req: transformer.h.31.input_layernorm.bias
Grad req: transformer.ln_f.weight
Grad req: transformer.ln_f.bias
{'loss': 1.0048, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.03}
{'loss': 1.005, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.06}
{'loss': 0.9859, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.1}
{'loss': 0.9852, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.13}
{'loss': 0.9293, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.16}
{'eval_loss': 0.8763375282287598, 'eval_runtime': 445.6034, 'eval_samples_per_second': 22.428, 'eval_steps_per_second': 2.805, 'epoch': 0.16}
{'loss': 0.9168, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.19}
{'loss': 0.8605, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.22}
{'loss': 0.8058, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.26}
{'loss': 0.8237, 'learning_rate': 3e-06, 'epoch': 0.29}
{'loss': 0.7972, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.32}
{'eval_loss': 0.7415624260902405, 'eval_runtime': 458.8771, 'eval_samples_per_second': 21.779, 'eval_steps_per_second': 2.724, 'epoch': 0.32}
{'loss': 0.7955, 'learning_rate': 3.6666666666666666e-06, 'epoch': 0.35}
{'loss': 0.7904, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.38}
{'loss': 0.7713, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.42}
{'loss': 0.764, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.45}
{'loss': 0.7674, 'learning_rate': 5e-06, 'epoch': 0.48}
{'eval_loss': 0.720748782157898, 'eval_runtime': 451.9743, 'eval_samples_per_second': 22.112, 'eval_steps_per_second': 2.766, 'epoch': 0.48}
{'loss': 0.7642, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.51}
{'loss': 0.7597, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.54}
{'loss': 0.7656, 'learning_rate': 6e-06, 'epoch': 0.58}
{'loss': 0.7684, 'learning_rate': 6.333333333333333e-06, 'epoch': 0.61}
{'loss': 0.7459, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.64}
{'eval_loss': 0.705405056476593, 'eval_runtime': 439.9755, 'eval_samples_per_second': 22.715, 'eval_steps_per_second': 2.841, 'epoch': 0.64}
{'loss': 0.741, 'learning_rate': 7e-06, 'epoch': 0.67}
{'loss': 0.735, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.7}
{'loss': 0.7192, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.74}
{'loss': 0.7377, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.77}
{'loss': 0.7328, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.8}
{'eval_loss': 0.6931250691413879, 'eval_runtime': 441.758, 'eval_samples_per_second': 22.623, 'eval_steps_per_second': 2.83, 'epoch': 0.8}
{'loss': 0.7073, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.83}
{'loss': 0.7232, 'learning_rate': 9e-06, 'epoch': 0.86}
{'loss': 0.7129, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.9}
{'loss': 0.713, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.93}
{'loss': 0.7, 'learning_rate': 1e-05, 'epoch': 0.96}
{'eval_loss': 0.6813886761665344, 'eval_runtime': 444.9539, 'eval_samples_per_second': 22.461, 'eval_steps_per_second': 2.809, 'epoch': 0.96}
{'loss': 0.7112, 'learning_rate': 9.989690721649485e-06, 'epoch': 0.99}
{'loss': 0.7136, 'learning_rate': 9.97938144329897e-06, 'epoch': 1.02}
{'loss': 0.7014, 'learning_rate': 9.969072164948454e-06, 'epoch': 1.06}
{'loss': 0.6758, 'learning_rate': 9.958762886597939e-06, 'epoch': 1.09}
{'loss': 0.6764, 'learning_rate': 9.948453608247423e-06, 'epoch': 1.12}
{'eval_loss': 0.6700891852378845, 'eval_runtime': 453.5519, 'eval_samples_per_second': 22.035, 'eval_steps_per_second': 2.756, 'epoch': 1.12}
{'loss': 0.6754, 'learning_rate': 9.938144329896908e-06, 'epoch': 1.15}
{'loss': 0.6709, 'learning_rate': 9.927835051546392e-06, 'epoch': 1.18}
{'loss': 0.6785, 'learning_rate': 9.917525773195877e-06, 'epoch': 1.22}
{'loss': 0.6871, 'learning_rate': 9.907216494845361e-06, 'epoch': 1.25}
{'loss': 0.6724, 'learning_rate': 9.896907216494846e-06, 'epoch': 1.28}
{'eval_loss': 0.664438009262085, 'eval_runtime': 450.8653, 'eval_samples_per_second': 22.166, 'eval_steps_per_second': 2.772, 'epoch': 1.28}
{'loss': 0.6888, 'learning_rate': 9.88659793814433e-06, 'epoch': 1.31}
{'loss': 0.6708, 'learning_rate': 9.876288659793815e-06, 'epoch': 1.34}
{'loss': 0.6474, 'learning_rate': 9.8659793814433e-06, 'epoch': 1.38}
{'loss': 0.6529, 'learning_rate': 9.855670103092784e-06, 'epoch': 1.41}
{'loss': 0.6481, 'learning_rate': 9.84536082474227e-06, 'epoch': 1.44}
{'eval_loss': 0.6591201424598694, 'eval_runtime': 440.1119, 'eval_samples_per_second': 22.708, 'eval_steps_per_second': 2.84, 'epoch': 1.44}
{'loss': 0.6691, 'learning_rate': 9.835051546391753e-06, 'epoch': 1.47}
{'loss': 0.6642, 'learning_rate': 9.824742268041238e-06, 'epoch': 1.5}
{'loss': 0.6671, 'learning_rate': 9.814432989690722e-06, 'epoch': 1.54}
{'loss': 0.6713, 'learning_rate': 9.804123711340207e-06, 'epoch': 1.57}
{'loss': 0.6856, 'learning_rate': 9.793814432989691e-06, 'epoch': 1.6}
{'eval_loss': 0.6543143391609192, 'eval_runtime': 450.2049, 'eval_samples_per_second': 22.199, 'eval_steps_per_second': 2.777, 'epoch': 1.6}
{'loss': 0.6616, 'learning_rate': 9.783505154639176e-06, 'epoch': 1.63}
{'loss': 0.6388, 'learning_rate': 9.77319587628866e-06, 'epoch': 1.66}
{'loss': 0.6691, 'learning_rate': 9.762886597938145e-06, 'epoch': 1.7}
{'loss': 0.6584, 'learning_rate': 9.752577319587629e-06, 'epoch': 1.73}
{'loss': 0.655, 'learning_rate': 9.742268041237114e-06, 'epoch': 1.76}
{'eval_loss': 0.6496097445487976, 'eval_runtime': 450.8493, 'eval_samples_per_second': 22.167, 'eval_steps_per_second': 2.773, 'epoch': 1.76}
{'loss': 0.6547, 'learning_rate': 9.731958762886598e-06, 'epoch': 1.79}
{'loss': 0.6676, 'learning_rate': 9.721649484536083e-06, 'epoch': 1.82}
{'loss': 0.6406, 'learning_rate': 9.711340206185567e-06, 'epoch': 1.86}
{'loss': 0.6406, 'learning_rate': 9.701030927835052e-06, 'epoch': 1.89}
{'loss': 0.6529, 'learning_rate': 9.690721649484536e-06, 'epoch': 1.92}
{'eval_loss': 0.6470625400543213, 'eval_runtime': 447.8598, 'eval_samples_per_second': 22.315, 'eval_steps_per_second': 2.791, 'epoch': 1.92}
{'loss': 0.6445, 'learning_rate': 9.68041237113402e-06, 'epoch': 1.95}
{'loss': 0.6571, 'learning_rate': 9.670103092783505e-06, 'epoch': 1.98}
{'loss': 0.6328, 'learning_rate': 9.659793814432991e-06, 'epoch': 2.02}
{'loss': 0.6097, 'learning_rate': 9.649484536082476e-06, 'epoch': 2.05}
{'loss': 0.6167, 'learning_rate': 9.63917525773196e-06, 'epoch': 2.08}
{'eval_loss': 0.645190417766571, 'eval_runtime': 451.4782, 'eval_samples_per_second': 22.136, 'eval_steps_per_second': 2.769, 'epoch': 2.08}
{'loss': 0.6321, 'learning_rate': 9.628865979381445e-06, 'epoch': 2.11}
{'loss': 0.606, 'learning_rate': 9.61855670103093e-06, 'epoch': 2.14}
{'loss': 0.625, 'learning_rate': 9.608247422680414e-06, 'epoch': 2.18}
{'loss': 0.6193, 'learning_rate': 9.597938144329899e-06, 'epoch': 2.21}
{'loss': 0.6172, 'learning_rate': 9.587628865979383e-06, 'epoch': 2.24}
