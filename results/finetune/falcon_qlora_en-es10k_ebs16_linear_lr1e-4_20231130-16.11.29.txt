====================================================================================================
FINETUNING PARAMETERS:
base model: tiiuae/falcon-7b
--------------------------------------------------
train_split: [:20000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/falcon_qlora_en-es10k_ebs16_linear_lr1e-4_20231130-16.11.29
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
max_steps: 10000
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 50
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
====================================================================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 20000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 20000
})
False
False
{'loss': 1.0292, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.01}
{'loss': 0.9788, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.02}
{'loss': 0.9859, 'learning_rate': 1e-05, 'epoch': 0.02}
{'loss': 1.0087, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.03}
{'loss': 0.8969, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.04}
{'eval_loss': 0.8137558102607727, 'eval_runtime': 752.2821, 'eval_samples_per_second': 13.285, 'eval_steps_per_second': 1.662, 'epoch': 0.04}
{'loss': 0.8782, 'learning_rate': 2e-05, 'epoch': 0.05}
{'loss': 0.8269, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.06}
{'loss': 0.8442, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.06}
{'loss': 0.7979, 'learning_rate': 3e-05, 'epoch': 0.07}
{'loss': 0.7931, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.08}
{'eval_loss': 0.7478495240211487, 'eval_runtime': 741.9763, 'eval_samples_per_second': 13.469, 'eval_steps_per_second': 1.685, 'epoch': 0.08}
{'loss': 0.7748, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.09}
{'loss': 0.7899, 'learning_rate': 4e-05, 'epoch': 0.1}
{'loss': 0.7821, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.1}
{'loss': 0.7486, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.11}
{'loss': 0.7678, 'learning_rate': 5e-05, 'epoch': 0.12}
{'eval_loss': 0.730708122253418, 'eval_runtime': 777.2684, 'eval_samples_per_second': 12.858, 'eval_steps_per_second': 1.608, 'epoch': 0.12}
{'loss': 0.7842, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.13}
{'loss': 0.7209, 'learning_rate': 5.666666666666667e-05, 'epoch': 0.14}
{'loss': 0.7268, 'learning_rate': 6e-05, 'epoch': 0.14}
{'loss': 0.7896, 'learning_rate': 6.333333333333333e-05, 'epoch': 0.15}
{'loss': 0.7523, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.16}
{'eval_loss': 0.7180294394493103, 'eval_runtime': 766.5595, 'eval_samples_per_second': 13.037, 'eval_steps_per_second': 1.631, 'epoch': 0.16}
{'loss': 0.7213, 'learning_rate': 7e-05, 'epoch': 0.17}
{'loss': 0.7744, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.18}
{'loss': 0.7539, 'learning_rate': 7.666666666666667e-05, 'epoch': 0.18}
{'loss': 0.7706, 'learning_rate': 8e-05, 'epoch': 0.19}
{'loss': 0.7475, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.2}
{'eval_loss': 0.704207181930542, 'eval_runtime': 766.2134, 'eval_samples_per_second': 13.043, 'eval_steps_per_second': 1.631, 'epoch': 0.2}
{'loss': 0.7543, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.21}
{'loss': 0.7116, 'learning_rate': 9e-05, 'epoch': 0.22}
{'loss': 0.7593, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.22}
{'loss': 0.6969, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.23}
{'loss': 0.7313, 'learning_rate': 0.0001, 'epoch': 0.24}
{'eval_loss': 0.6999054551124573, 'eval_runtime': 763.868, 'eval_samples_per_second': 13.083, 'eval_steps_per_second': 1.636, 'epoch': 0.24}
{'loss': 0.6843, 'learning_rate': 9.989690721649485e-05, 'epoch': 0.25}
{'loss': 0.7347, 'learning_rate': 9.97938144329897e-05, 'epoch': 0.26}
{'loss': 0.7037, 'learning_rate': 9.969072164948454e-05, 'epoch': 0.26}
{'loss': 0.7511, 'learning_rate': 9.958762886597939e-05, 'epoch': 0.27}
{'loss': 0.7406, 'learning_rate': 9.948453608247423e-05, 'epoch': 0.28}
{'eval_loss': 0.6908416748046875, 'eval_runtime': 759.6899, 'eval_samples_per_second': 13.155, 'eval_steps_per_second': 1.645, 'epoch': 0.28}
{'loss': 0.7394, 'learning_rate': 9.938144329896908e-05, 'epoch': 0.29}
{'loss': 0.7122, 'learning_rate': 9.927835051546392e-05, 'epoch': 0.3}
{'loss': 0.7417, 'learning_rate': 9.917525773195877e-05, 'epoch': 0.3}
{'loss': 0.7296, 'learning_rate': 9.907216494845362e-05, 'epoch': 0.31}
{'loss': 0.6925, 'learning_rate': 9.896907216494846e-05, 'epoch': 0.32}
{'eval_loss': 0.6835533976554871, 'eval_runtime': 747.3258, 'eval_samples_per_second': 13.373, 'eval_steps_per_second': 1.673, 'epoch': 0.32}
{'loss': 0.7352, 'learning_rate': 9.88659793814433e-05, 'epoch': 0.33}
{'loss': 0.7153, 'learning_rate': 9.876288659793816e-05, 'epoch': 0.34}
{'loss': 0.6796, 'learning_rate': 9.8659793814433e-05, 'epoch': 0.34}
{'loss': 0.715, 'learning_rate': 9.855670103092784e-05, 'epoch': 0.35}
{'loss': 0.7249, 'learning_rate': 9.845360824742269e-05, 'epoch': 0.36}
{'eval_loss': 0.6802791357040405, 'eval_runtime': 748.2759, 'eval_samples_per_second': 13.356, 'eval_steps_per_second': 1.671, 'epoch': 0.36}
{'loss': 0.707, 'learning_rate': 9.835051546391753e-05, 'epoch': 0.37}
{'loss': 0.7162, 'learning_rate': 9.824742268041237e-05, 'epoch': 0.38}
{'loss': 0.6934, 'learning_rate': 9.814432989690721e-05, 'epoch': 0.38}
{'loss': 0.6758, 'learning_rate': 9.804123711340207e-05, 'epoch': 0.39}
{'loss': 0.6819, 'learning_rate': 9.793814432989691e-05, 'epoch': 0.4}
{'eval_loss': 0.6763344407081604, 'eval_runtime': 759.7166, 'eval_samples_per_second': 13.155, 'eval_steps_per_second': 1.645, 'epoch': 0.4}
{'loss': 0.7372, 'learning_rate': 9.783505154639175e-05, 'epoch': 0.41}
{'loss': 0.684, 'learning_rate': 9.77319587628866e-05, 'epoch': 0.42}
{'loss': 0.6798, 'learning_rate': 9.762886597938145e-05, 'epoch': 0.42}
{'loss': 0.7096, 'learning_rate': 9.752577319587629e-05, 'epoch': 0.43}
{'loss': 0.6971, 'learning_rate': 9.742268041237114e-05, 'epoch': 0.44}
{'eval_loss': 0.6640433669090271, 'eval_runtime': 767.8033, 'eval_samples_per_second': 13.016, 'eval_steps_per_second': 1.628, 'epoch': 0.44}
{'loss': 0.6485, 'learning_rate': 9.731958762886598e-05, 'epoch': 0.45}
{'loss': 0.6963, 'learning_rate': 9.721649484536083e-05, 'epoch': 0.46}
{'loss': 0.7015, 'learning_rate': 9.711340206185567e-05, 'epoch': 0.46}
{'loss': 0.6861, 'learning_rate': 9.701030927835052e-05, 'epoch': 0.47}
{'loss': 0.6872, 'learning_rate': 9.690721649484537e-05, 'epoch': 0.48}
