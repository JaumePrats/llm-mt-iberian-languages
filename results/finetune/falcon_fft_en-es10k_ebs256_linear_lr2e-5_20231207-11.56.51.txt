==================================================
FINETUNING PARAMETERS:
base model: tiiuae/falcon-7b
--------------------------------------------------
train_split: [:20000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/falcon_fft_en-es10k_ebs256_linear_lr2e-5_20231207-11.56.51
--------------------------------------------------
learning_rate: 2e-05
lr_scheduler_type: linear
effective batch size: 256
  per_device_train_batch_size: 16
  gradient_accumulation_steps: 16
  CUDA Devices: 3,4,5,6
num_train_epochs: 3
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 0.01
--------------------------------------------------
bf16: True
==================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 20000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 20000
})
False
False
Grad req: transformer.word_embeddings.weight
Grad req: transformer.h.0.self_attention.query_key_value.weight
Grad req: transformer.h.0.self_attention.dense.weight
Grad req: transformer.h.0.mlp.dense_h_to_4h.weight
Grad req: transformer.h.0.mlp.dense_4h_to_h.weight
Grad req: transformer.h.0.input_layernorm.weight
Grad req: transformer.h.0.input_layernorm.bias
Grad req: transformer.h.1.self_attention.query_key_value.weight
Grad req: transformer.h.1.self_attention.dense.weight
Grad req: transformer.h.1.mlp.dense_h_to_4h.weight
Grad req: transformer.h.1.mlp.dense_4h_to_h.weight
Grad req: transformer.h.1.input_layernorm.weight
Grad req: transformer.h.1.input_layernorm.bias
Grad req: transformer.h.2.self_attention.query_key_value.weight
Grad req: transformer.h.2.self_attention.dense.weight
Grad req: transformer.h.2.mlp.dense_h_to_4h.weight
Grad req: transformer.h.2.mlp.dense_4h_to_h.weight
Grad req: transformer.h.2.input_layernorm.weight
Grad req: transformer.h.2.input_layernorm.bias
Grad req: transformer.h.3.self_attention.query_key_value.weight
Grad req: transformer.h.3.self_attention.dense.weight
Grad req: transformer.h.3.mlp.dense_h_to_4h.weight
Grad req: transformer.h.3.mlp.dense_4h_to_h.weight
Grad req: transformer.h.3.input_layernorm.weight
Grad req: transformer.h.3.input_layernorm.bias
Grad req: transformer.h.4.self_attention.query_key_value.weight
Grad req: transformer.h.4.self_attention.dense.weight
Grad req: transformer.h.4.mlp.dense_h_to_4h.weight
Grad req: transformer.h.4.mlp.dense_4h_to_h.weight
Grad req: transformer.h.4.input_layernorm.weight
Grad req: transformer.h.4.input_layernorm.bias
Grad req: transformer.h.5.self_attention.query_key_value.weight
Grad req: transformer.h.5.self_attention.dense.weight
Grad req: transformer.h.5.mlp.dense_h_to_4h.weight
Grad req: transformer.h.5.mlp.dense_4h_to_h.weight
Grad req: transformer.h.5.input_layernorm.weight
Grad req: transformer.h.5.input_layernorm.bias
Grad req: transformer.h.6.self_attention.query_key_value.weight
Grad req: transformer.h.6.self_attention.dense.weight
Grad req: transformer.h.6.mlp.dense_h_to_4h.weight
Grad req: transformer.h.6.mlp.dense_4h_to_h.weight
Grad req: transformer.h.6.input_layernorm.weight
Grad req: transformer.h.6.input_layernorm.bias
Grad req: transformer.h.7.self_attention.query_key_value.weight
Grad req: transformer.h.7.self_attention.dense.weight
Grad req: transformer.h.7.mlp.dense_h_to_4h.weight
Grad req: transformer.h.7.mlp.dense_4h_to_h.weight
Grad req: transformer.h.7.input_layernorm.weight
Grad req: transformer.h.7.input_layernorm.bias
Grad req: transformer.h.8.self_attention.query_key_value.weight
Grad req: transformer.h.8.self_attention.dense.weight
Grad req: transformer.h.8.mlp.dense_h_to_4h.weight
Grad req: transformer.h.8.mlp.dense_4h_to_h.weight
Grad req: transformer.h.8.input_layernorm.weight
Grad req: transformer.h.8.input_layernorm.bias
Grad req: transformer.h.9.self_attention.query_key_value.weight
Grad req: transformer.h.9.self_attention.dense.weight
Grad req: transformer.h.9.mlp.dense_h_to_4h.weight
Grad req: transformer.h.9.mlp.dense_4h_to_h.weight
Grad req: transformer.h.9.input_layernorm.weight
Grad req: transformer.h.9.input_layernorm.bias
Grad req: transformer.h.10.self_attention.query_key_value.weight
Grad req: transformer.h.10.self_attention.dense.weight
Grad req: transformer.h.10.mlp.dense_h_to_4h.weight
Grad req: transformer.h.10.mlp.dense_4h_to_h.weight
Grad req: transformer.h.10.input_layernorm.weight
Grad req: transformer.h.10.input_layernorm.bias
Grad req: transformer.h.11.self_attention.query_key_value.weight
Grad req: transformer.h.11.self_attention.dense.weight
Grad req: transformer.h.11.mlp.dense_h_to_4h.weight
Grad req: transformer.h.11.mlp.dense_4h_to_h.weight
Grad req: transformer.h.11.input_layernorm.weight
Grad req: transformer.h.11.input_layernorm.bias
Grad req: transformer.h.12.self_attention.query_key_value.weight
Grad req: transformer.h.12.self_attention.dense.weight
Grad req: transformer.h.12.mlp.dense_h_to_4h.weight
Grad req: transformer.h.12.mlp.dense_4h_to_h.weight
Grad req: transformer.h.12.input_layernorm.weight
Grad req: transformer.h.12.input_layernorm.bias
Grad req: transformer.h.13.self_attention.query_key_value.weight
Grad req: transformer.h.13.self_attention.dense.weight
Grad req: transformer.h.13.mlp.dense_h_to_4h.weight
Grad req: transformer.h.13.mlp.dense_4h_to_h.weight
Grad req: transformer.h.13.input_layernorm.weight
Grad req: transformer.h.13.input_layernorm.bias
Grad req: transformer.h.14.self_attention.query_key_value.weight
Grad req: transformer.h.14.self_attention.dense.weight
Grad req: transformer.h.14.mlp.dense_h_to_4h.weight
Grad req: transformer.h.14.mlp.dense_4h_to_h.weight
Grad req: transformer.h.14.input_layernorm.weight
Grad req: transformer.h.14.input_layernorm.bias
Grad req: transformer.h.15.self_attention.query_key_value.weight
Grad req: transformer.h.15.self_attention.dense.weight
Grad req: transformer.h.15.mlp.dense_h_to_4h.weight
Grad req: transformer.h.15.mlp.dense_4h_to_h.weight
Grad req: transformer.h.15.input_layernorm.weight
Grad req: transformer.h.15.input_layernorm.bias
Grad req: transformer.h.16.self_attention.query_key_value.weight
Grad req: transformer.h.16.self_attention.dense.weight
Grad req: transformer.h.16.mlp.dense_h_to_4h.weight
Grad req: transformer.h.16.mlp.dense_4h_to_h.weight
Grad req: transformer.h.16.input_layernorm.weight
Grad req: transformer.h.16.input_layernorm.bias
Grad req: transformer.h.17.self_attention.query_key_value.weight
Grad req: transformer.h.17.self_attention.dense.weight
Grad req: transformer.h.17.mlp.dense_h_to_4h.weight
Grad req: transformer.h.17.mlp.dense_4h_to_h.weight
Grad req: transformer.h.17.input_layernorm.weight
Grad req: transformer.h.17.input_layernorm.bias
Grad req: transformer.h.18.self_attention.query_key_value.weight
Grad req: transformer.h.18.self_attention.dense.weight
Grad req: transformer.h.18.mlp.dense_h_to_4h.weight
Grad req: transformer.h.18.mlp.dense_4h_to_h.weight
Grad req: transformer.h.18.input_layernorm.weight
Grad req: transformer.h.18.input_layernorm.bias
Grad req: transformer.h.19.self_attention.query_key_value.weight
Grad req: transformer.h.19.self_attention.dense.weight
Grad req: transformer.h.19.mlp.dense_h_to_4h.weight
Grad req: transformer.h.19.mlp.dense_4h_to_h.weight
Grad req: transformer.h.19.input_layernorm.weight
Grad req: transformer.h.19.input_layernorm.bias
Grad req: transformer.h.20.self_attention.query_key_value.weight
Grad req: transformer.h.20.self_attention.dense.weight
Grad req: transformer.h.20.mlp.dense_h_to_4h.weight
Grad req: transformer.h.20.mlp.dense_4h_to_h.weight
Grad req: transformer.h.20.input_layernorm.weight
Grad req: transformer.h.20.input_layernorm.bias
Grad req: transformer.h.21.self_attention.query_key_value.weight
Grad req: transformer.h.21.self_attention.dense.weight
Grad req: transformer.h.21.mlp.dense_h_to_4h.weight
Grad req: transformer.h.21.mlp.dense_4h_to_h.weight
Grad req: transformer.h.21.input_layernorm.weight
Grad req: transformer.h.21.input_layernorm.bias
Grad req: transformer.h.22.self_attention.query_key_value.weight
Grad req: transformer.h.22.self_attention.dense.weight
Grad req: transformer.h.22.mlp.dense_h_to_4h.weight
Grad req: transformer.h.22.mlp.dense_4h_to_h.weight
Grad req: transformer.h.22.input_layernorm.weight
Grad req: transformer.h.22.input_layernorm.bias
Grad req: transformer.h.23.self_attention.query_key_value.weight
Grad req: transformer.h.23.self_attention.dense.weight
Grad req: transformer.h.23.mlp.dense_h_to_4h.weight
Grad req: transformer.h.23.mlp.dense_4h_to_h.weight
Grad req: transformer.h.23.input_layernorm.weight
Grad req: transformer.h.23.input_layernorm.bias
Grad req: transformer.h.24.self_attention.query_key_value.weight
Grad req: transformer.h.24.self_attention.dense.weight
Grad req: transformer.h.24.mlp.dense_h_to_4h.weight
Grad req: transformer.h.24.mlp.dense_4h_to_h.weight
Grad req: transformer.h.24.input_layernorm.weight
Grad req: transformer.h.24.input_layernorm.bias
Grad req: transformer.h.25.self_attention.query_key_value.weight
Grad req: transformer.h.25.self_attention.dense.weight
Grad req: transformer.h.25.mlp.dense_h_to_4h.weight
Grad req: transformer.h.25.mlp.dense_4h_to_h.weight
Grad req: transformer.h.25.input_layernorm.weight
Grad req: transformer.h.25.input_layernorm.bias
Grad req: transformer.h.26.self_attention.query_key_value.weight
Grad req: transformer.h.26.self_attention.dense.weight
Grad req: transformer.h.26.mlp.dense_h_to_4h.weight
Grad req: transformer.h.26.mlp.dense_4h_to_h.weight
Grad req: transformer.h.26.input_layernorm.weight
Grad req: transformer.h.26.input_layernorm.bias
Grad req: transformer.h.27.self_attention.query_key_value.weight
Grad req: transformer.h.27.self_attention.dense.weight
Grad req: transformer.h.27.mlp.dense_h_to_4h.weight
Grad req: transformer.h.27.mlp.dense_4h_to_h.weight
Grad req: transformer.h.27.input_layernorm.weight
Grad req: transformer.h.27.input_layernorm.bias
Grad req: transformer.h.28.self_attention.query_key_value.weight
Grad req: transformer.h.28.self_attention.dense.weight
Grad req: transformer.h.28.mlp.dense_h_to_4h.weight
Grad req: transformer.h.28.mlp.dense_4h_to_h.weight
Grad req: transformer.h.28.input_layernorm.weight
Grad req: transformer.h.28.input_layernorm.bias
Grad req: transformer.h.29.self_attention.query_key_value.weight
Grad req: transformer.h.29.self_attention.dense.weight
Grad req: transformer.h.29.mlp.dense_h_to_4h.weight
Grad req: transformer.h.29.mlp.dense_4h_to_h.weight
Grad req: transformer.h.29.input_layernorm.weight
Grad req: transformer.h.29.input_layernorm.bias
Grad req: transformer.h.30.self_attention.query_key_value.weight
Grad req: transformer.h.30.self_attention.dense.weight
Grad req: transformer.h.30.mlp.dense_h_to_4h.weight
Grad req: transformer.h.30.mlp.dense_4h_to_h.weight
Grad req: transformer.h.30.input_layernorm.weight
Grad req: transformer.h.30.input_layernorm.bias
Grad req: transformer.h.31.self_attention.query_key_value.weight
Grad req: transformer.h.31.self_attention.dense.weight
Grad req: transformer.h.31.mlp.dense_h_to_4h.weight
Grad req: transformer.h.31.mlp.dense_4h_to_h.weight
Grad req: transformer.h.31.input_layernorm.weight
Grad req: transformer.h.31.input_layernorm.bias
Grad req: transformer.ln_f.weight
Grad req: transformer.ln_f.bias
model.hf_device_map: {'transformer.word_embeddings': 0, 'lm_head': 0, 'transformer.h.0': 0, 'transformer.h.1': 0, 'transformer.h.2': 0, 'transformer.h.3': 0, 'transformer.h.4': 0, 'transformer.h.5': 0, 'transformer.h.6': 0, 'transformer.h.7': 1, 'transformer.h.8': 1, 'transformer.h.9': 1, 'transformer.h.10': 1, 'transformer.h.11': 1, 'transformer.h.12': 1, 'transformer.h.13': 1, 'transformer.h.14': 1, 'transformer.h.15': 1, 'transformer.h.16': 2, 'transformer.h.17': 2, 'transformer.h.18': 2, 'transformer.h.19': 2, 'transformer.h.20': 2, 'transformer.h.21': 2, 'transformer.h.22': 2, 'transformer.h.23': 2, 'transformer.h.24': 2, 'transformer.h.25': 3, 'transformer.h.26': 3, 'transformer.h.27': 3, 'transformer.h.28': 3, 'transformer.h.29': 3, 'transformer.h.30': 3, 'transformer.h.31': 3, 'transformer.ln_f': 3}
{'loss': 1.0229, 'learning_rate': 2.5e-06, 'epoch': 0.01}
{'loss': 1.0263, 'learning_rate': 5e-06, 'epoch': 0.03}
{'loss': 1.0004, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.04}
{'eval_loss': 0.8847054243087769, 'eval_runtime': 432.8088, 'eval_samples_per_second': 23.091, 'eval_steps_per_second': 2.888, 'epoch': 0.04}
{'loss': 0.9623, 'learning_rate': 1e-05, 'epoch': 0.05}
{'loss': 0.9603, 'learning_rate': 1.25e-05, 'epoch': 0.06}
{'loss': 0.8174, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.08}
{'eval_loss': 0.7510833740234375, 'eval_runtime': 433.8044, 'eval_samples_per_second': 23.038, 'eval_steps_per_second': 2.881, 'epoch': 0.08}
{'loss': 0.819, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.09}
{'loss': 0.8164, 'learning_rate': 2e-05, 'epoch': 0.1}
{'loss': 0.7624, 'learning_rate': 1.991150442477876e-05, 'epoch': 0.12}
{'eval_loss': 0.7285309433937073, 'eval_runtime': 434.6906, 'eval_samples_per_second': 22.991, 'eval_steps_per_second': 2.876, 'epoch': 0.12}
{'loss': 0.8007, 'learning_rate': 1.9823008849557524e-05, 'epoch': 0.13}
{'loss': 0.7361, 'learning_rate': 1.9734513274336283e-05, 'epoch': 0.14}
{'loss': 0.7664, 'learning_rate': 1.9646017699115046e-05, 'epoch': 0.15}
{'eval_loss': 0.7159786224365234, 'eval_runtime': 434.4447, 'eval_samples_per_second': 23.004, 'eval_steps_per_second': 2.877, 'epoch': 0.15}
{'loss': 0.7554, 'learning_rate': 1.9557522123893806e-05, 'epoch': 0.17}
{'loss': 0.7848, 'learning_rate': 1.946902654867257e-05, 'epoch': 0.18}
{'loss': 0.7481, 'learning_rate': 1.9380530973451328e-05, 'epoch': 0.19}
{'eval_loss': 0.7033713459968567, 'eval_runtime': 434.1645, 'eval_samples_per_second': 23.019, 'eval_steps_per_second': 2.879, 'epoch': 0.19}
{'loss': 0.7511, 'learning_rate': 1.929203539823009e-05, 'epoch': 0.2}
{'loss': 0.7494, 'learning_rate': 1.9203539823008853e-05, 'epoch': 0.22}
{'loss': 0.7224, 'learning_rate': 1.9115044247787613e-05, 'epoch': 0.23}
{'eval_loss': 0.6947566270828247, 'eval_runtime': 432.5793, 'eval_samples_per_second': 23.103, 'eval_steps_per_second': 2.89, 'epoch': 0.23}
{'loss': 0.7372, 'learning_rate': 1.9026548672566376e-05, 'epoch': 0.24}
{'loss': 0.729, 'learning_rate': 1.8938053097345135e-05, 'epoch': 0.26}
{'loss': 0.7459, 'learning_rate': 1.8849557522123894e-05, 'epoch': 0.27}
{'eval_loss': 0.6882656216621399, 'eval_runtime': 433.8434, 'eval_samples_per_second': 23.036, 'eval_steps_per_second': 2.881, 'epoch': 0.27}
{'loss': 0.7403, 'learning_rate': 1.8761061946902657e-05, 'epoch': 0.28}
{'loss': 0.74, 'learning_rate': 1.8672566371681417e-05, 'epoch': 0.29}
{'loss': 0.7471, 'learning_rate': 1.858407079646018e-05, 'epoch': 0.31}
{'eval_loss': 0.6832366585731506, 'eval_runtime': 433.6643, 'eval_samples_per_second': 23.045, 'eval_steps_per_second': 2.882, 'epoch': 0.31}
{'loss': 0.7022, 'learning_rate': 1.849557522123894e-05, 'epoch': 0.32}
{'loss': 0.7501, 'learning_rate': 1.8407079646017702e-05, 'epoch': 0.33}
{'loss': 0.7002, 'learning_rate': 1.831858407079646e-05, 'epoch': 0.35}
{'eval_loss': 0.6782090067863464, 'eval_runtime': 433.6711, 'eval_samples_per_second': 23.045, 'eval_steps_per_second': 2.882, 'epoch': 0.35}
{'loss': 0.7351, 'learning_rate': 1.823008849557522e-05, 'epoch': 0.36}
{'loss': 0.7423, 'learning_rate': 1.8141592920353983e-05, 'epoch': 0.37}
{'loss': 0.7258, 'learning_rate': 1.8053097345132743e-05, 'epoch': 0.38}
{'eval_loss': 0.6749411225318909, 'eval_runtime': 433.7199, 'eval_samples_per_second': 23.043, 'eval_steps_per_second': 2.882, 'epoch': 0.38}
{'loss': 0.6942, 'learning_rate': 1.7964601769911506e-05, 'epoch': 0.4}
{'loss': 0.7364, 'learning_rate': 1.7876106194690265e-05, 'epoch': 0.41}
{'loss': 0.6791, 'learning_rate': 1.7787610619469028e-05, 'epoch': 0.42}
{'eval_loss': 0.6727935075759888, 'eval_runtime': 434.0945, 'eval_samples_per_second': 23.023, 'eval_steps_per_second': 2.88, 'epoch': 0.42}
{'loss': 0.7451, 'learning_rate': 1.769911504424779e-05, 'epoch': 0.44}
{'loss': 0.6806, 'learning_rate': 1.761061946902655e-05, 'epoch': 0.45}
{'loss': 0.7083, 'learning_rate': 1.7522123893805313e-05, 'epoch': 0.46}
{'eval_loss': 0.6688963174819946, 'eval_runtime': 435.8877, 'eval_samples_per_second': 22.928, 'eval_steps_per_second': 2.868, 'epoch': 0.46}
{'loss': 0.7297, 'learning_rate': 1.7433628318584072e-05, 'epoch': 0.47}
{'loss': 0.693, 'learning_rate': 1.7345132743362835e-05, 'epoch': 0.49}
{'loss': 0.7268, 'learning_rate': 1.7256637168141594e-05, 'epoch': 0.5}
{'eval_loss': 0.6656962633132935, 'eval_runtime': 433.7935, 'eval_samples_per_second': 23.039, 'eval_steps_per_second': 2.882, 'epoch': 0.5}
{'loss': 0.6768, 'learning_rate': 1.7168141592920354e-05, 'epoch': 0.51}
{'loss': 0.7131, 'learning_rate': 1.7079646017699117e-05, 'epoch': 0.52}
{'loss': 0.7177, 'learning_rate': 1.6991150442477876e-05, 'epoch': 0.54}
{'eval_loss': 0.6636163592338562, 'eval_runtime': 434.0899, 'eval_samples_per_second': 23.023, 'eval_steps_per_second': 2.88, 'epoch': 0.54}
{'loss': 0.7141, 'learning_rate': 1.690265486725664e-05, 'epoch': 0.55}
{'loss': 0.7445, 'learning_rate': 1.68141592920354e-05, 'epoch': 0.56}
{'loss': 0.6732, 'learning_rate': 1.672566371681416e-05, 'epoch': 0.58}
{'eval_loss': 0.6622632741928101, 'eval_runtime': 434.0957, 'eval_samples_per_second': 23.023, 'eval_steps_per_second': 2.88, 'epoch': 0.58}
{'loss': 0.7181, 'learning_rate': 1.663716814159292e-05, 'epoch': 0.59}
{'loss': 0.7116, 'learning_rate': 1.6548672566371683e-05, 'epoch': 0.6}
{'loss': 0.7174, 'learning_rate': 1.6460176991150443e-05, 'epoch': 0.61}
{'eval_loss': 0.6598998308181763, 'eval_runtime': 434.1428, 'eval_samples_per_second': 23.02, 'eval_steps_per_second': 2.879, 'epoch': 0.61}
{'loss': 0.6906, 'learning_rate': 1.6371681415929206e-05, 'epoch': 0.63}
{'loss': 0.7105, 'learning_rate': 1.628318584070797e-05, 'epoch': 0.64}
{'loss': 0.6801, 'learning_rate': 1.6194690265486728e-05, 'epoch': 0.65}
{'eval_loss': 0.6582918763160706, 'eval_runtime': 434.1744, 'eval_samples_per_second': 23.018, 'eval_steps_per_second': 2.879, 'epoch': 0.65}
{'loss': 0.7231, 'learning_rate': 1.6106194690265487e-05, 'epoch': 0.67}
{'loss': 0.657, 'learning_rate': 1.601769911504425e-05, 'epoch': 0.68}
{'loss': 0.6997, 'learning_rate': 1.592920353982301e-05, 'epoch': 0.69}
{'eval_loss': 0.6554567217826843, 'eval_runtime': 433.4859, 'eval_samples_per_second': 23.055, 'eval_steps_per_second': 2.884, 'epoch': 0.69}
{'loss': 0.6914, 'learning_rate': 1.5840707964601772e-05, 'epoch': 0.7}
{'loss': 0.6825, 'learning_rate': 1.5752212389380532e-05, 'epoch': 0.72}
{'loss': 0.709, 'learning_rate': 1.5663716814159295e-05, 'epoch': 0.73}
{'eval_loss': 0.6533482074737549, 'eval_runtime': 434.6127, 'eval_samples_per_second': 22.995, 'eval_steps_per_second': 2.876, 'epoch': 0.73}
{'loss': 0.6718, 'learning_rate': 1.5575221238938054e-05, 'epoch': 0.74}
{'loss': 0.6884, 'learning_rate': 1.5486725663716813e-05, 'epoch': 0.76}
{'loss': 0.6756, 'learning_rate': 1.5398230088495576e-05, 'epoch': 0.77}
{'eval_loss': 0.6510154604911804, 'eval_runtime': 433.8937, 'eval_samples_per_second': 23.033, 'eval_steps_per_second': 2.881, 'epoch': 0.77}
{'loss': 0.7083, 'learning_rate': 1.5309734513274336e-05, 'epoch': 0.78}
{'loss': 0.6989, 'learning_rate': 1.5221238938053098e-05, 'epoch': 0.79}
{'loss': 0.6623, 'learning_rate': 1.513274336283186e-05, 'epoch': 0.81}
{'eval_loss': 0.6498352885246277, 'eval_runtime': 434.2797, 'eval_samples_per_second': 23.013, 'eval_steps_per_second': 2.878, 'epoch': 0.81}
{'loss': 0.6766, 'learning_rate': 1.5044247787610619e-05, 'epoch': 0.82}
{'loss': 0.659, 'learning_rate': 1.4955752212389383e-05, 'epoch': 0.83}
{'loss': 0.667, 'learning_rate': 1.4867256637168143e-05, 'epoch': 0.84}
{'eval_loss': 0.648377001285553, 'eval_runtime': 434.1363, 'eval_samples_per_second': 23.02, 'eval_steps_per_second': 2.879, 'epoch': 0.84}
{'loss': 0.6872, 'learning_rate': 1.4778761061946904e-05, 'epoch': 0.86}
{'loss': 0.6954, 'learning_rate': 1.4690265486725665e-05, 'epoch': 0.87}
{'loss': 0.6565, 'learning_rate': 1.4601769911504426e-05, 'epoch': 0.88}
{'eval_loss': 0.6471708416938782, 'eval_runtime': 433.2382, 'eval_samples_per_second': 23.068, 'eval_steps_per_second': 2.885, 'epoch': 0.88}
{'loss': 0.6901, 'learning_rate': 1.4513274336283187e-05, 'epoch': 0.9}
{'loss': 0.6667, 'learning_rate': 1.4424778761061948e-05, 'epoch': 0.91}
{'loss': 0.7014, 'learning_rate': 1.433628318584071e-05, 'epoch': 0.92}
{'eval_loss': 0.6464411616325378, 'eval_runtime': 433.4108, 'eval_samples_per_second': 23.059, 'eval_steps_per_second': 2.884, 'epoch': 0.92}
{'loss': 0.6382, 'learning_rate': 1.424778761061947e-05, 'epoch': 0.93}
{'loss': 0.6561, 'learning_rate': 1.4159292035398232e-05, 'epoch': 0.95}
{'loss': 0.6949, 'learning_rate': 1.4070796460176991e-05, 'epoch': 0.96}
{'eval_loss': 0.6453467011451721, 'eval_runtime': 433.7481, 'eval_samples_per_second': 23.041, 'eval_steps_per_second': 2.882, 'epoch': 0.96}
{'loss': 0.6567, 'learning_rate': 1.3982300884955752e-05, 'epoch': 0.97}
{'loss': 0.7006, 'learning_rate': 1.3893805309734513e-05, 'epoch': 0.99}
{'loss': 0.6954, 'learning_rate': 1.3805309734513275e-05, 'epoch': 1.0}
{'eval_loss': 0.6452956795692444, 'eval_runtime': 438.2769, 'eval_samples_per_second': 22.803, 'eval_steps_per_second': 2.852, 'epoch': 1.0}
{'loss': 0.6397, 'learning_rate': 1.3716814159292036e-05, 'epoch': 1.01}
{'loss': 0.5868, 'learning_rate': 1.3628318584070797e-05, 'epoch': 1.02}
{'loss': 0.6116, 'learning_rate': 1.353982300884956e-05, 'epoch': 1.04}
{'eval_loss': 0.6450855135917664, 'eval_runtime': 433.567, 'eval_samples_per_second': 23.051, 'eval_steps_per_second': 2.883, 'epoch': 1.04}
{'loss': 0.6251, 'learning_rate': 1.345132743362832e-05, 'epoch': 1.05}
{'loss': 0.612, 'learning_rate': 1.3362831858407082e-05, 'epoch': 1.06}
{'loss': 0.5749, 'learning_rate': 1.3274336283185843e-05, 'epoch': 1.08}
{'eval_loss': 0.6453170776367188, 'eval_runtime': 434.7121, 'eval_samples_per_second': 22.99, 'eval_steps_per_second': 2.875, 'epoch': 1.08}
{'loss': 0.6343, 'learning_rate': 1.3185840707964604e-05, 'epoch': 1.09}
{'loss': 0.5906, 'learning_rate': 1.3097345132743363e-05, 'epoch': 1.1}
{'loss': 0.6169, 'learning_rate': 1.3008849557522125e-05, 'epoch': 1.11}
{'eval_loss': 0.6438980102539062, 'eval_runtime': 434.0348, 'eval_samples_per_second': 23.026, 'eval_steps_per_second': 2.88, 'epoch': 1.11}
{'loss': 0.5976, 'learning_rate': 1.2920353982300886e-05, 'epoch': 1.13}
{'loss': 0.669, 'learning_rate': 1.2831858407079647e-05, 'epoch': 1.14}
{'loss': 0.6247, 'learning_rate': 1.2743362831858408e-05, 'epoch': 1.15}
