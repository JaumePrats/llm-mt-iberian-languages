==================================================
FINETUNING PARAMETERS:
base model: projecte-aina/aguila-7b
--------------------------------------------------
train_split: [:200000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/tr4_aguila_qlora_en-es100k_ebs256-4x1x64_linear_lr2e-4_20231209-13.49.58
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
effective batch size: 64
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 64
  CUDA Devices: 2,3,4,5
num_train_epochs: 3
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 0.11111
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
==================================================
==================================================
FINETUNING PARAMETERS:
base model: projecte-aina/aguila-7b
--------------------------------------------------
train_split: [:200000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/tr4_aguila_qlora_en-es100k_ebs256-4x1x64_linear_lr2e-4_20231209-13.49.58
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
effective batch size: 64
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 64
  CUDA Devices: 2,3,4,5
num_train_epochs: 3
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 0.11111
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
==================================================
==================================================
FINETUNING PARAMETERS:
base model: projecte-aina/aguila-7b
--------------------------------------------------
train_split: [:200000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/tr4_aguila_qlora_en-es100k_ebs256-4x1x64_linear_lr2e-4_20231209-13.49.58
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
effective batch size: 64
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 64
  CUDA Devices: 2,3,4,5
num_train_epochs: 3
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 0.11111
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
==================================================
==================================================
FINETUNING PARAMETERS:
base model: projecte-aina/aguila-7b
--------------------------------------------------
train_split: [:200000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/tr4_aguila_qlora_en-es100k_ebs256-4x1x64_linear_lr2e-4_20231209-13.49.58
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
effective batch size: 64
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 64
  CUDA Devices: 2,3,4,5
num_train_epochs: 3
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 0.11111
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
==================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 200000
})
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 200000
})
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 200000
})
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 200000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 200000
})
False
False
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 200000
})
False
False
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 200000
})
False
False
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 200000
})
False
False
{'loss': 2.0196, 'learning_rate': 1.4084507042253521e-06, 'epoch': 0.0}
{'loss': 2.0834, 'learning_rate': 2.8169014084507042e-06, 'epoch': 0.0}
{'loss': 2.0096, 'learning_rate': 4.225352112676056e-06, 'epoch': 0.0}
{'loss': 2.0288, 'learning_rate': 5.6338028169014084e-06, 'epoch': 0.01}
{'loss': 1.9494, 'learning_rate': 7.042253521126762e-06, 'epoch': 0.01}
{'loss': 2.0181, 'learning_rate': 8.450704225352112e-06, 'epoch': 0.01}
{'loss': 2.0628, 'learning_rate': 9.859154929577465e-06, 'epoch': 0.01}
{'loss': 2.0387, 'learning_rate': 1.1267605633802817e-05, 'epoch': 0.01}
{'loss': 2.0099, 'learning_rate': 1.267605633802817e-05, 'epoch': 0.01}
{'loss': 2.0887, 'learning_rate': 1.4084507042253523e-05, 'epoch': 0.01}
{'loss': 2.0074, 'learning_rate': 1.5492957746478872e-05, 'epoch': 0.01}
{'loss': 1.9389, 'learning_rate': 1.6901408450704224e-05, 'epoch': 0.02}
{'loss': 1.9915, 'learning_rate': 1.830985915492958e-05, 'epoch': 0.02}
{'loss': 2.0379, 'learning_rate': 1.971830985915493e-05, 'epoch': 0.02}
{'loss': 2.0208, 'learning_rate': 2.112676056338028e-05, 'epoch': 0.02}
{'loss': 1.9053, 'learning_rate': 2.2535211267605634e-05, 'epoch': 0.02}
{'loss': 1.9775, 'learning_rate': 2.3943661971830986e-05, 'epoch': 0.02}
{'loss': 2.0238, 'learning_rate': 2.535211267605634e-05, 'epoch': 0.02}
{'loss': 1.9915, 'learning_rate': 2.676056338028169e-05, 'epoch': 0.02}
{'loss': 1.9875, 'learning_rate': 2.8169014084507046e-05, 'epoch': 0.03}
{'loss': 1.9552, 'learning_rate': 2.9577464788732395e-05, 'epoch': 0.03}
{'loss': 2.032, 'learning_rate': 3.0985915492957744e-05, 'epoch': 0.03}
{'loss': 1.9706, 'learning_rate': 3.23943661971831e-05, 'epoch': 0.03}
{'loss': 1.9868, 'learning_rate': 3.380281690140845e-05, 'epoch': 0.03}
{'loss': 1.9522, 'learning_rate': 3.5211267605633805e-05, 'epoch': 0.03}
{'loss': 1.9943, 'learning_rate': 3.661971830985916e-05, 'epoch': 0.03}
{'loss': 1.9362, 'learning_rate': 3.802816901408451e-05, 'epoch': 0.03}
{'loss': 1.8869, 'learning_rate': 3.943661971830986e-05, 'epoch': 0.04}
{'loss': 1.9632, 'learning_rate': 4.0845070422535214e-05, 'epoch': 0.04}
{'loss': 1.8496, 'learning_rate': 4.225352112676056e-05, 'epoch': 0.04}
{'loss': 1.8586, 'learning_rate': 4.366197183098591e-05, 'epoch': 0.04}
{'loss': 1.8575, 'learning_rate': 4.507042253521127e-05, 'epoch': 0.04}
{'loss': 1.8156, 'learning_rate': 4.647887323943662e-05, 'epoch': 0.04}
{'loss': 1.8423, 'learning_rate': 4.788732394366197e-05, 'epoch': 0.04}
{'loss': 1.7492, 'learning_rate': 4.929577464788733e-05, 'epoch': 0.04}
{'loss': 1.7563, 'learning_rate': 5.070422535211268e-05, 'epoch': 0.05}
{'loss': 1.7313, 'learning_rate': 5.2112676056338026e-05, 'epoch': 0.05}
{'loss': 1.6275, 'learning_rate': 5.352112676056338e-05, 'epoch': 0.05}
{'loss': 1.5899, 'learning_rate': 5.492957746478874e-05, 'epoch': 0.05}
{'loss': 1.584, 'learning_rate': 5.633802816901409e-05, 'epoch': 0.05}
{'loss': 1.5834, 'learning_rate': 5.774647887323944e-05, 'epoch': 0.05}
{'loss': 1.523, 'learning_rate': 5.915492957746479e-05, 'epoch': 0.05}
{'loss': 1.4776, 'learning_rate': 6.056338028169014e-05, 'epoch': 0.06}
{'loss': 1.4689, 'learning_rate': 6.197183098591549e-05, 'epoch': 0.06}
{'loss': 1.4454, 'learning_rate': 6.338028169014085e-05, 'epoch': 0.06}
{'loss': 1.4154, 'learning_rate': 6.47887323943662e-05, 'epoch': 0.06}
{'loss': 1.414, 'learning_rate': 6.619718309859155e-05, 'epoch': 0.06}
{'loss': 1.3679, 'learning_rate': 6.76056338028169e-05, 'epoch': 0.06}
{'loss': 1.315, 'learning_rate': 6.901408450704226e-05, 'epoch': 0.06}
{'loss': 1.2683, 'learning_rate': 7.042253521126761e-05, 'epoch': 0.06}
{'loss': 1.3031, 'learning_rate': 7.183098591549297e-05, 'epoch': 0.07}
{'loss': 1.2338, 'learning_rate': 7.323943661971832e-05, 'epoch': 0.07}
{'loss': 1.218, 'learning_rate': 7.464788732394367e-05, 'epoch': 0.07}
{'loss': 1.1943, 'learning_rate': 7.605633802816902e-05, 'epoch': 0.07}
{'loss': 1.1091, 'learning_rate': 7.746478873239437e-05, 'epoch': 0.07}
{'loss': 1.0124, 'learning_rate': 7.887323943661972e-05, 'epoch': 0.07}
{'loss': 0.9547, 'learning_rate': 8.028169014084508e-05, 'epoch': 0.07}
{'loss': 0.9027, 'learning_rate': 8.169014084507043e-05, 'epoch': 0.07}
{'loss': 0.9238, 'learning_rate': 8.309859154929578e-05, 'epoch': 0.08}
{'loss': 0.9135, 'learning_rate': 8.450704225352113e-05, 'epoch': 0.08}
{'loss': 0.8748, 'learning_rate': 8.591549295774647e-05, 'epoch': 0.08}
{'loss': 0.893, 'learning_rate': 8.732394366197182e-05, 'epoch': 0.08}
{'loss': 0.9416, 'learning_rate': 8.873239436619719e-05, 'epoch': 0.08}
{'loss': 0.8961, 'learning_rate': 9.014084507042254e-05, 'epoch': 0.08}
{'loss': 0.8823, 'learning_rate': 9.15492957746479e-05, 'epoch': 0.08}
{'loss': 0.9128, 'learning_rate': 9.295774647887325e-05, 'epoch': 0.08}
{'loss': 0.8846, 'learning_rate': 9.43661971830986e-05, 'epoch': 0.09}
{'loss': 0.8755, 'learning_rate': 9.577464788732394e-05, 'epoch': 0.09}
{'loss': 0.9032, 'learning_rate': 9.718309859154931e-05, 'epoch': 0.09}
{'loss': 0.8641, 'learning_rate': 9.859154929577466e-05, 'epoch': 0.09}
{'loss': 0.881, 'learning_rate': 0.0001, 'epoch': 0.09}
{'loss': 0.8621, 'learning_rate': 9.995598591549296e-05, 'epoch': 0.09}
{'loss': 0.9216, 'learning_rate': 9.991197183098592e-05, 'epoch': 0.09}
{'loss': 0.8652, 'learning_rate': 9.986795774647888e-05, 'epoch': 0.09}
{'loss': 0.8503, 'learning_rate': 9.982394366197183e-05, 'epoch': 0.1}
{'loss': 0.8611, 'learning_rate': 9.977992957746479e-05, 'epoch': 0.1}
{'loss': 0.9229, 'learning_rate': 9.973591549295775e-05, 'epoch': 0.1}
{'loss': 0.9059, 'learning_rate': 9.969190140845071e-05, 'epoch': 0.1}
{'loss': 0.8427, 'learning_rate': 9.964788732394367e-05, 'epoch': 0.1}
{'loss': 0.8905, 'learning_rate': 9.960387323943663e-05, 'epoch': 0.1}
{'loss': 0.8779, 'learning_rate': 9.955985915492959e-05, 'epoch': 0.1}
{'loss': 0.8272, 'learning_rate': 9.951584507042255e-05, 'epoch': 0.1}
{'loss': 0.8562, 'learning_rate': 9.947183098591549e-05, 'epoch': 0.11}
{'loss': 0.9045, 'learning_rate': 9.942781690140845e-05, 'epoch': 0.11}
{'loss': 0.8814, 'learning_rate': 9.938380281690141e-05, 'epoch': 0.11}
{'loss': 0.84, 'learning_rate': 9.933978873239437e-05, 'epoch': 0.11}
{'loss': 0.8269, 'learning_rate': 9.929577464788733e-05, 'epoch': 0.11}
{'loss': 0.857, 'learning_rate': 9.925176056338029e-05, 'epoch': 0.11}
{'loss': 0.8728, 'learning_rate': 9.920774647887324e-05, 'epoch': 0.11}
{'loss': 0.8418, 'learning_rate': 9.916373239436621e-05, 'epoch': 0.12}
{'loss': 0.8672, 'learning_rate': 9.911971830985915e-05, 'epoch': 0.12}
{'loss': 0.8908, 'learning_rate': 9.907570422535211e-05, 'epoch': 0.12}
{'loss': 0.8225, 'learning_rate': 9.903169014084507e-05, 'epoch': 0.12}
{'loss': 0.8526, 'learning_rate': 9.898767605633803e-05, 'epoch': 0.12}
{'loss': 0.8402, 'learning_rate': 9.894366197183099e-05, 'epoch': 0.12}
{'loss': 0.8749, 'learning_rate': 9.889964788732394e-05, 'epoch': 0.12}
{'loss': 0.8563, 'learning_rate': 9.88556338028169e-05, 'epoch': 0.12}
{'loss': 0.8496, 'learning_rate': 9.881161971830987e-05, 'epoch': 0.13}
{'loss': 0.8361, 'learning_rate': 9.876760563380282e-05, 'epoch': 0.13}
{'loss': 0.8911, 'learning_rate': 9.872359154929578e-05, 'epoch': 0.13}
{'loss': 0.8694, 'learning_rate': 9.867957746478874e-05, 'epoch': 0.13}
{'loss': 0.8222, 'learning_rate': 9.86355633802817e-05, 'epoch': 0.13}
{'loss': 0.8362, 'learning_rate': 9.859154929577466e-05, 'epoch': 0.13}
{'loss': 0.8071, 'learning_rate': 9.85475352112676e-05, 'epoch': 0.13}
{'loss': 0.8463, 'learning_rate': 9.850352112676056e-05, 'epoch': 0.13}
{'loss': 0.8539, 'learning_rate': 9.845950704225353e-05, 'epoch': 0.14}
{'loss': 0.8161, 'learning_rate': 9.841549295774648e-05, 'epoch': 0.14}
{'loss': 0.8133, 'learning_rate': 9.837147887323944e-05, 'epoch': 0.14}
{'loss': 0.8268, 'learning_rate': 9.83274647887324e-05, 'epoch': 0.14}
{'loss': 0.8465, 'learning_rate': 9.828345070422536e-05, 'epoch': 0.14}
{'loss': 0.843, 'learning_rate': 9.823943661971832e-05, 'epoch': 0.14}
{'loss': 0.8374, 'learning_rate': 9.819542253521126e-05, 'epoch': 0.14}
{'loss': 0.8405, 'learning_rate': 9.815140845070422e-05, 'epoch': 0.14}
{'loss': 0.7771, 'learning_rate': 9.81073943661972e-05, 'epoch': 0.15}
{'loss': 0.8121, 'learning_rate': 9.806338028169014e-05, 'epoch': 0.15}
{'loss': 0.8471, 'learning_rate': 9.80193661971831e-05, 'epoch': 0.15}
{'loss': 0.8363, 'learning_rate': 9.797535211267606e-05, 'epoch': 0.15}
{'loss': 0.8418, 'learning_rate': 9.793133802816902e-05, 'epoch': 0.15}
{'loss': 0.8446, 'learning_rate': 9.788732394366198e-05, 'epoch': 0.15}
{'loss': 0.821, 'learning_rate': 9.784330985915493e-05, 'epoch': 0.15}
{'loss': 0.829, 'learning_rate': 9.779929577464789e-05, 'epoch': 0.15}
{'loss': 0.8068, 'learning_rate': 9.775528169014086e-05, 'epoch': 0.16}
{'loss': 0.8658, 'learning_rate': 9.77112676056338e-05, 'epoch': 0.16}
{'loss': 0.849, 'learning_rate': 9.766725352112677e-05, 'epoch': 0.16}
{'loss': 0.7935, 'learning_rate': 9.762323943661971e-05, 'epoch': 0.16}
{'loss': 0.8414, 'learning_rate': 9.757922535211268e-05, 'epoch': 0.16}
{'loss': 0.8186, 'learning_rate': 9.753521126760564e-05, 'epoch': 0.16}
{'loss': 0.7988, 'learning_rate': 9.749119718309859e-05, 'epoch': 0.16}
{'loss': 0.7693, 'learning_rate': 9.744718309859155e-05, 'epoch': 0.17}
{'loss': 0.8179, 'learning_rate': 9.740316901408452e-05, 'epoch': 0.17}
{'loss': 0.8041, 'learning_rate': 9.735915492957747e-05, 'epoch': 0.17}
{'loss': 0.8384, 'learning_rate': 9.731514084507043e-05, 'epoch': 0.17}
{'loss': 0.8322, 'learning_rate': 9.727112676056337e-05, 'epoch': 0.17}
{'loss': 0.807, 'learning_rate': 9.722711267605635e-05, 'epoch': 0.17}
{'loss': 0.8166, 'learning_rate': 9.718309859154931e-05, 'epoch': 0.17}
{'loss': 0.8008, 'learning_rate': 9.713908450704225e-05, 'epoch': 0.17}
{'loss': 0.8129, 'learning_rate': 9.709507042253521e-05, 'epoch': 0.18}
{'loss': 0.8602, 'learning_rate': 9.705105633802819e-05, 'epoch': 0.18}
{'loss': 0.7894, 'learning_rate': 9.700704225352113e-05, 'epoch': 0.18}
{'loss': 0.7994, 'learning_rate': 9.696302816901409e-05, 'epoch': 0.18}
{'loss': 0.8236, 'learning_rate': 9.691901408450704e-05, 'epoch': 0.18}
{'loss': 0.8613, 'learning_rate': 9.687500000000001e-05, 'epoch': 0.18}
{'loss': 0.7739, 'learning_rate': 9.683098591549297e-05, 'epoch': 0.18}
{'loss': 0.7978, 'learning_rate': 9.678697183098592e-05, 'epoch': 0.18}
{'loss': 0.7795, 'learning_rate': 9.674295774647888e-05, 'epoch': 0.19}
{'loss': 0.7833, 'learning_rate': 9.669894366197183e-05, 'epoch': 0.19}
{'loss': 0.829, 'learning_rate': 9.66549295774648e-05, 'epoch': 0.19}
{'loss': 0.7977, 'learning_rate': 9.661091549295775e-05, 'epoch': 0.19}
{'loss': 0.7786, 'learning_rate': 9.65669014084507e-05, 'epoch': 0.19}
{'loss': 0.7936, 'learning_rate': 9.652288732394367e-05, 'epoch': 0.19}
{'loss': 0.8028, 'learning_rate': 9.647887323943663e-05, 'epoch': 0.19}
{'loss': 0.7924, 'learning_rate': 9.643485915492958e-05, 'epoch': 0.19}
{'loss': 0.8209, 'learning_rate': 9.639084507042254e-05, 'epoch': 0.2}
{'loss': 0.78, 'learning_rate': 9.63468309859155e-05, 'epoch': 0.2}
{'loss': 0.789, 'learning_rate': 9.630281690140846e-05, 'epoch': 0.2}
{'loss': 0.8198, 'learning_rate': 9.625880281690142e-05, 'epoch': 0.2}
{'loss': 0.7747, 'learning_rate': 9.621478873239436e-05, 'epoch': 0.2}
{'loss': 0.7674, 'learning_rate': 9.617077464788734e-05, 'epoch': 0.2}
{'loss': 0.8396, 'learning_rate': 9.61267605633803e-05, 'epoch': 0.2}
{'loss': 0.7844, 'learning_rate': 9.608274647887324e-05, 'epoch': 0.2}
{'loss': 0.7893, 'learning_rate': 9.60387323943662e-05, 'epoch': 0.21}
{'loss': 0.8001, 'learning_rate': 9.599471830985916e-05, 'epoch': 0.21}
{'loss': 0.7995, 'learning_rate': 9.595070422535212e-05, 'epoch': 0.21}
{'loss': 0.7754, 'learning_rate': 9.590669014084508e-05, 'epoch': 0.21}
{'loss': 0.8308, 'learning_rate': 9.586267605633803e-05, 'epoch': 0.21}
{'loss': 0.8041, 'learning_rate': 9.5818661971831e-05, 'epoch': 0.21}
{'loss': 0.861, 'learning_rate': 9.577464788732394e-05, 'epoch': 0.21}
{'loss': 0.7827, 'learning_rate': 9.57306338028169e-05, 'epoch': 0.22}
{'loss': 0.8013, 'learning_rate': 9.568661971830986e-05, 'epoch': 0.22}
{'loss': 0.7714, 'learning_rate': 9.564260563380282e-05, 'epoch': 0.22}
{'loss': 0.8073, 'learning_rate': 9.559859154929578e-05, 'epoch': 0.22}
{'loss': 0.8211, 'learning_rate': 9.555457746478874e-05, 'epoch': 0.22}
{'loss': 0.7862, 'learning_rate': 9.551056338028169e-05, 'epoch': 0.22}
{'loss': 0.781, 'learning_rate': 9.546654929577465e-05, 'epoch': 0.22}
{'loss': 0.8379, 'learning_rate': 9.542253521126761e-05, 'epoch': 0.22}
{'loss': 0.8015, 'learning_rate': 9.537852112676057e-05, 'epoch': 0.23}
{'loss': 0.7506, 'learning_rate': 9.533450704225353e-05, 'epoch': 0.23}
{'loss': 0.7785, 'learning_rate': 9.529049295774649e-05, 'epoch': 0.23}
{'loss': 0.8067, 'learning_rate': 9.524647887323945e-05, 'epoch': 0.23}
{'loss': 0.767, 'learning_rate': 9.52024647887324e-05, 'epoch': 0.23}
{'loss': 0.7749, 'learning_rate': 9.515845070422535e-05, 'epoch': 0.23}
{'loss': 0.7984, 'learning_rate': 9.511443661971831e-05, 'epoch': 0.23}
{'loss': 0.7746, 'learning_rate': 9.507042253521127e-05, 'epoch': 0.23}
{'loss': 0.7545, 'learning_rate': 9.502640845070423e-05, 'epoch': 0.24}
{'loss': 0.7878, 'learning_rate': 9.498239436619719e-05, 'epoch': 0.24}
{'loss': 0.7712, 'learning_rate': 9.493838028169015e-05, 'epoch': 0.24}
{'loss': 0.7607, 'learning_rate': 9.489436619718311e-05, 'epoch': 0.24}
{'loss': 0.7975, 'learning_rate': 9.485035211267607e-05, 'epoch': 0.24}
{'loss': 0.7914, 'learning_rate': 9.480633802816901e-05, 'epoch': 0.24}
{'loss': 0.7898, 'learning_rate': 9.476232394366197e-05, 'epoch': 0.24}
{'loss': 0.7449, 'learning_rate': 9.471830985915493e-05, 'epoch': 0.24}
{'loss': 0.8002, 'learning_rate': 9.467429577464789e-05, 'epoch': 0.25}
{'loss': 0.7464, 'learning_rate': 9.463028169014085e-05, 'epoch': 0.25}
{'loss': 0.7936, 'learning_rate': 9.458626760563381e-05, 'epoch': 0.25}
{'loss': 0.7671, 'learning_rate': 9.454225352112677e-05, 'epoch': 0.25}
{'loss': 0.7853, 'learning_rate': 9.449823943661972e-05, 'epoch': 0.25}
{'loss': 0.784, 'learning_rate': 9.445422535211268e-05, 'epoch': 0.25}
{'loss': 0.7779, 'learning_rate': 9.441021126760564e-05, 'epoch': 0.25}
{'loss': 0.7898, 'learning_rate': 9.43661971830986e-05, 'epoch': 0.25}
{'loss': 0.7981, 'learning_rate': 9.432218309859156e-05, 'epoch': 0.26}
{'loss': 0.7584, 'learning_rate': 9.427816901408451e-05, 'epoch': 0.26}
{'loss': 0.7727, 'learning_rate': 9.423415492957746e-05, 'epoch': 0.26}
{'loss': 0.7707, 'learning_rate': 9.419014084507043e-05, 'epoch': 0.26}
{'loss': 0.7731, 'learning_rate': 9.414612676056338e-05, 'epoch': 0.26}
{'loss': 0.7641, 'learning_rate': 9.410211267605634e-05, 'epoch': 0.26}
{'loss': 0.7495, 'learning_rate': 9.40580985915493e-05, 'epoch': 0.26}
{'loss': 0.7951, 'learning_rate': 9.401408450704226e-05, 'epoch': 0.26}
{'loss': 0.7659, 'learning_rate': 9.397007042253522e-05, 'epoch': 0.27}
{'loss': 0.7665, 'learning_rate': 9.392605633802818e-05, 'epoch': 0.27}
{'loss': 0.8227, 'learning_rate': 9.388204225352112e-05, 'epoch': 0.27}
{'loss': 0.7987, 'learning_rate': 9.38380281690141e-05, 'epoch': 0.27}
{'loss': 0.7964, 'learning_rate': 9.379401408450704e-05, 'epoch': 0.27}
{'loss': 0.7877, 'learning_rate': 9.375e-05, 'epoch': 0.27}
{'loss': 0.7801, 'learning_rate': 9.370598591549296e-05, 'epoch': 0.27}
{'loss': 0.7748, 'learning_rate': 9.366197183098592e-05, 'epoch': 0.28}
{'loss': 0.7377, 'learning_rate': 9.361795774647888e-05, 'epoch': 0.28}
{'loss': 0.776, 'learning_rate': 9.357394366197183e-05, 'epoch': 0.28}
{'loss': 0.731, 'learning_rate': 9.352992957746479e-05, 'epoch': 0.28}
{'loss': 0.7496, 'learning_rate': 9.348591549295776e-05, 'epoch': 0.28}
{'loss': 0.7692, 'learning_rate': 9.34419014084507e-05, 'epoch': 0.28}
{'loss': 0.7631, 'learning_rate': 9.339788732394366e-05, 'epoch': 0.28}
{'loss': 0.8014, 'learning_rate': 9.335387323943662e-05, 'epoch': 0.28}
{'loss': 0.7386, 'learning_rate': 9.330985915492958e-05, 'epoch': 0.29}
{'loss': 0.7975, 'learning_rate': 9.326584507042254e-05, 'epoch': 0.29}
{'loss': 0.7624, 'learning_rate': 9.322183098591549e-05, 'epoch': 0.29}
{'loss': 0.7308, 'learning_rate': 9.317781690140845e-05, 'epoch': 0.29}
{'loss': 0.7718, 'learning_rate': 9.313380281690142e-05, 'epoch': 0.29}
{'loss': 0.7825, 'learning_rate': 9.308978873239437e-05, 'epoch': 0.29}
{'loss': 0.7589, 'learning_rate': 9.304577464788733e-05, 'epoch': 0.29}
{'loss': 0.7813, 'learning_rate': 9.300176056338029e-05, 'epoch': 0.29}
{'loss': 0.7538, 'learning_rate': 9.295774647887325e-05, 'epoch': 0.3}
{'loss': 0.7137, 'learning_rate': 9.29137323943662e-05, 'epoch': 0.3}
{'loss': 0.7323, 'learning_rate': 9.286971830985915e-05, 'epoch': 0.3}
{'loss': 0.7829, 'learning_rate': 9.282570422535211e-05, 'epoch': 0.3}
{'loss': 0.7974, 'learning_rate': 9.278169014084508e-05, 'epoch': 0.3}
{'loss': 0.7713, 'learning_rate': 9.273767605633803e-05, 'epoch': 0.3}
{'loss': 0.7317, 'learning_rate': 9.269366197183099e-05, 'epoch': 0.3}
{'loss': 0.7537, 'learning_rate': 9.264964788732394e-05, 'epoch': 0.3}
{'loss': 0.7259, 'learning_rate': 9.260563380281691e-05, 'epoch': 0.31}
{'loss': 0.7693, 'learning_rate': 9.256161971830987e-05, 'epoch': 0.31}
{'loss': 0.7599, 'learning_rate': 9.251760563380281e-05, 'epoch': 0.31}
{'loss': 0.7676, 'learning_rate': 9.247359154929577e-05, 'epoch': 0.31}
{'loss': 0.784, 'learning_rate': 9.242957746478875e-05, 'epoch': 0.31}
{'loss': 0.7421, 'learning_rate': 9.23855633802817e-05, 'epoch': 0.31}
{'loss': 0.7464, 'learning_rate': 9.234154929577465e-05, 'epoch': 0.31}
{'loss': 0.765, 'learning_rate': 9.22975352112676e-05, 'epoch': 0.31}
{'loss': 0.7516, 'learning_rate': 9.225352112676057e-05, 'epoch': 0.32}
{'loss': 0.778, 'learning_rate': 9.220950704225353e-05, 'epoch': 0.32}
{'loss': 0.7754, 'learning_rate': 9.216549295774648e-05, 'epoch': 0.32}
{'loss': 0.7845, 'learning_rate': 9.212147887323944e-05, 'epoch': 0.32}
{'loss': 0.7297, 'learning_rate': 9.207746478873241e-05, 'epoch': 0.32}
{'loss': 0.7586, 'learning_rate': 9.203345070422536e-05, 'epoch': 0.32}
{'loss': 0.7411, 'learning_rate': 9.198943661971832e-05, 'epoch': 0.32}
{'loss': 0.759, 'learning_rate': 9.194542253521126e-05, 'epoch': 0.33}
{'loss': 0.7794, 'learning_rate': 9.190140845070423e-05, 'epoch': 0.33}
{'loss': 0.7439, 'learning_rate': 9.18573943661972e-05, 'epoch': 0.33}
{'loss': 0.7582, 'learning_rate': 9.181338028169014e-05, 'epoch': 0.33}
{'loss': 0.7658, 'learning_rate': 9.17693661971831e-05, 'epoch': 0.33}
{'loss': 0.7624, 'learning_rate': 9.172535211267606e-05, 'epoch': 0.33}
{'loss': 0.7522, 'learning_rate': 9.168133802816902e-05, 'epoch': 0.33}
{'loss': 0.7557, 'learning_rate': 9.163732394366198e-05, 'epoch': 0.33}
{'eval_loss': 0.9109836220741272, 'eval_runtime': 190.7239, 'eval_samples_per_second': 52.4, 'eval_steps_per_second': 1.641, 'epoch': 0.33}
{'loss': 0.7713, 'learning_rate': 9.159330985915492e-05, 'epoch': 0.34}
{'loss': 0.724, 'learning_rate': 9.15492957746479e-05, 'epoch': 0.34}
{'loss': 0.7443, 'learning_rate': 9.150528169014086e-05, 'epoch': 0.34}
{'loss': 0.732, 'learning_rate': 9.14612676056338e-05, 'epoch': 0.34}
{'loss': 0.7669, 'learning_rate': 9.141725352112676e-05, 'epoch': 0.34}
{'loss': 0.7866, 'learning_rate': 9.137323943661972e-05, 'epoch': 0.34}
{'loss': 0.747, 'learning_rate': 9.132922535211268e-05, 'epoch': 0.34}
{'loss': 0.7391, 'learning_rate': 9.128521126760564e-05, 'epoch': 0.34}
{'loss': 0.723, 'learning_rate': 9.124119718309859e-05, 'epoch': 0.35}
{'loss': 0.7134, 'learning_rate': 9.119718309859156e-05, 'epoch': 0.35}
{'loss': 0.7722, 'learning_rate': 9.115316901408452e-05, 'epoch': 0.35}
{'loss': 0.7602, 'learning_rate': 9.110915492957747e-05, 'epoch': 0.35}
{'loss': 0.7628, 'learning_rate': 9.106514084507043e-05, 'epoch': 0.35}
{'loss': 0.7643, 'learning_rate': 9.102112676056339e-05, 'epoch': 0.35}
{'loss': 0.7459, 'learning_rate': 9.097711267605634e-05, 'epoch': 0.35}
{'loss': 0.7547, 'learning_rate': 9.09330985915493e-05, 'epoch': 0.35}
{'loss': 0.7604, 'learning_rate': 9.088908450704225e-05, 'epoch': 0.36}
{'loss': 0.7852, 'learning_rate': 9.084507042253522e-05, 'epoch': 0.36}
{'loss': 0.7564, 'learning_rate': 9.080105633802818e-05, 'epoch': 0.36}
{'loss': 0.7787, 'learning_rate': 9.075704225352113e-05, 'epoch': 0.36}
{'loss': 0.7665, 'learning_rate': 9.071302816901409e-05, 'epoch': 0.36}
{'loss': 0.7283, 'learning_rate': 9.066901408450705e-05, 'epoch': 0.36}
{'loss': 0.7599, 'learning_rate': 9.062500000000001e-05, 'epoch': 0.36}
{'loss': 0.7209, 'learning_rate': 9.058098591549297e-05, 'epoch': 0.36}
{'loss': 0.7186, 'learning_rate': 9.053697183098591e-05, 'epoch': 0.37}
{'loss': 0.768, 'learning_rate': 9.049295774647887e-05, 'epoch': 0.37}
{'loss': 0.7502, 'learning_rate': 9.044894366197183e-05, 'epoch': 0.37}
{'loss': 0.7389, 'learning_rate': 9.040492957746479e-05, 'epoch': 0.37}
{'loss': 0.738, 'learning_rate': 9.036091549295775e-05, 'epoch': 0.37}
{'loss': 0.732, 'learning_rate': 9.031690140845071e-05, 'epoch': 0.37}
{'loss': 0.694, 'learning_rate': 9.027288732394367e-05, 'epoch': 0.37}
{'loss': 0.7441, 'learning_rate': 9.022887323943663e-05, 'epoch': 0.38}
{'loss': 0.7257, 'learning_rate': 9.018485915492958e-05, 'epoch': 0.38}
{'loss': 0.7515, 'learning_rate': 9.014084507042254e-05, 'epoch': 0.38}
{'loss': 0.7486, 'learning_rate': 9.00968309859155e-05, 'epoch': 0.38}
{'loss': 0.7596, 'learning_rate': 9.005281690140845e-05, 'epoch': 0.38}
{'loss': 0.7204, 'learning_rate': 9.000880281690141e-05, 'epoch': 0.38}
{'loss': 0.7274, 'learning_rate': 8.996478873239437e-05, 'epoch': 0.38}
{'loss': 0.7244, 'learning_rate': 8.992077464788733e-05, 'epoch': 0.38}
{'loss': 0.747, 'learning_rate': 8.987676056338029e-05, 'epoch': 0.39}
{'loss': 0.715, 'learning_rate': 8.983274647887324e-05, 'epoch': 0.39}
{'loss': 0.7723, 'learning_rate': 8.97887323943662e-05, 'epoch': 0.39}
{'loss': 0.7523, 'learning_rate': 8.974471830985916e-05, 'epoch': 0.39}
{'loss': 0.7257, 'learning_rate': 8.970070422535212e-05, 'epoch': 0.39}
{'loss': 0.7784, 'learning_rate': 8.965669014084508e-05, 'epoch': 0.39}
{'loss': 0.7293, 'learning_rate': 8.961267605633804e-05, 'epoch': 0.39}
{'loss': 0.7273, 'learning_rate': 8.9568661971831e-05, 'epoch': 0.39}
{'loss': 0.7394, 'learning_rate': 8.952464788732394e-05, 'epoch': 0.4}
{'loss': 0.7459, 'learning_rate': 8.94806338028169e-05, 'epoch': 0.4}
{'loss': 0.7151, 'learning_rate': 8.943661971830986e-05, 'epoch': 0.4}
{'loss': 0.7415, 'learning_rate': 8.939260563380282e-05, 'epoch': 0.4}
{'loss': 0.7493, 'learning_rate': 8.934859154929578e-05, 'epoch': 0.4}
{'loss': 0.7446, 'learning_rate': 8.930457746478874e-05, 'epoch': 0.4}
{'loss': 0.7429, 'learning_rate': 8.92605633802817e-05, 'epoch': 0.4}
{'loss': 0.7621, 'learning_rate': 8.921654929577466e-05, 'epoch': 0.4}
{'loss': 0.7148, 'learning_rate': 8.91725352112676e-05, 'epoch': 0.41}
{'loss': 0.757, 'learning_rate': 8.912852112676056e-05, 'epoch': 0.41}
{'loss': 0.7353, 'learning_rate': 8.908450704225352e-05, 'epoch': 0.41}
{'loss': 0.7491, 'learning_rate': 8.904049295774648e-05, 'epoch': 0.41}
{'loss': 0.7353, 'learning_rate': 8.899647887323944e-05, 'epoch': 0.41}
{'loss': 0.7342, 'learning_rate': 8.89524647887324e-05, 'epoch': 0.41}
{'loss': 0.7092, 'learning_rate': 8.890845070422535e-05, 'epoch': 0.41}
{'loss': 0.7449, 'learning_rate': 8.886443661971832e-05, 'epoch': 0.41}
{'loss': 0.6972, 'learning_rate': 8.882042253521127e-05, 'epoch': 0.42}
{'loss': 0.7339, 'learning_rate': 8.877640845070423e-05, 'epoch': 0.42}
{'loss': 0.7324, 'learning_rate': 8.873239436619719e-05, 'epoch': 0.42}
{'loss': 0.7045, 'learning_rate': 8.868838028169015e-05, 'epoch': 0.42}
{'loss': 0.7053, 'learning_rate': 8.86443661971831e-05, 'epoch': 0.42}
{'loss': 0.7169, 'learning_rate': 8.860035211267606e-05, 'epoch': 0.42}
{'loss': 0.7096, 'learning_rate': 8.855633802816901e-05, 'epoch': 0.42}
{'loss': 0.7032, 'learning_rate': 8.851232394366198e-05, 'epoch': 0.42}
{'loss': 0.7157, 'learning_rate': 8.846830985915493e-05, 'epoch': 0.43}
{'loss': 0.6933, 'learning_rate': 8.842429577464789e-05, 'epoch': 0.43}
{'loss': 0.7354, 'learning_rate': 8.838028169014085e-05, 'epoch': 0.43}
{'loss': 0.7357, 'learning_rate': 8.833626760563381e-05, 'epoch': 0.43}
{'loss': 0.6998, 'learning_rate': 8.829225352112677e-05, 'epoch': 0.43}
{'loss': 0.7245, 'learning_rate': 8.824823943661971e-05, 'epoch': 0.43}
{'loss': 0.7384, 'learning_rate': 8.820422535211267e-05, 'epoch': 0.43}
{'loss': 0.7011, 'learning_rate': 8.816021126760565e-05, 'epoch': 0.44}
{'loss': 0.7331, 'learning_rate': 8.811619718309859e-05, 'epoch': 0.44}
{'loss': 0.7484, 'learning_rate': 8.807218309859155e-05, 'epoch': 0.44}
{'loss': 0.6927, 'learning_rate': 8.802816901408451e-05, 'epoch': 0.44}
{'loss': 0.7573, 'learning_rate': 8.798415492957747e-05, 'epoch': 0.44}
{'loss': 0.7421, 'learning_rate': 8.794014084507043e-05, 'epoch': 0.44}
{'loss': 0.7362, 'learning_rate': 8.789612676056338e-05, 'epoch': 0.44}
{'loss': 0.7453, 'learning_rate': 8.785211267605634e-05, 'epoch': 0.44}
{'loss': 0.7154, 'learning_rate': 8.780809859154931e-05, 'epoch': 0.45}
{'loss': 0.7252, 'learning_rate': 8.776408450704226e-05, 'epoch': 0.45}
{'loss': 0.7229, 'learning_rate': 8.772007042253521e-05, 'epoch': 0.45}
{'loss': 0.7334, 'learning_rate': 8.767605633802817e-05, 'epoch': 0.45}
{'loss': 0.7455, 'learning_rate': 8.763204225352113e-05, 'epoch': 0.45}
{'loss': 0.7301, 'learning_rate': 8.75880281690141e-05, 'epoch': 0.45}
{'loss': 0.7006, 'learning_rate': 8.754401408450704e-05, 'epoch': 0.45}
{'loss': 0.7454, 'learning_rate': 8.75e-05, 'epoch': 0.45}
{'loss': 0.7263, 'learning_rate': 8.745598591549297e-05, 'epoch': 0.46}
{'loss': 0.7464, 'learning_rate': 8.741197183098592e-05, 'epoch': 0.46}
{'loss': 0.7406, 'learning_rate': 8.736795774647888e-05, 'epoch': 0.46}
{'loss': 0.7094, 'learning_rate': 8.732394366197182e-05, 'epoch': 0.46}
{'loss': 0.705, 'learning_rate': 8.72799295774648e-05, 'epoch': 0.46}
{'loss': 0.7372, 'learning_rate': 8.723591549295776e-05, 'epoch': 0.46}
{'loss': 0.7466, 'learning_rate': 8.71919014084507e-05, 'epoch': 0.46}
{'loss': 0.7466, 'learning_rate': 8.714788732394366e-05, 'epoch': 0.46}
{'loss': 0.7337, 'learning_rate': 8.710387323943663e-05, 'epoch': 0.47}
{'loss': 0.7599, 'learning_rate': 8.705985915492958e-05, 'epoch': 0.47}
{'loss': 0.7324, 'learning_rate': 8.701584507042254e-05, 'epoch': 0.47}
{'loss': 0.7002, 'learning_rate': 8.697183098591549e-05, 'epoch': 0.47}
{'loss': 0.7365, 'learning_rate': 8.692781690140846e-05, 'epoch': 0.47}
{'loss': 0.7264, 'learning_rate': 8.688380281690142e-05, 'epoch': 0.47}
{'loss': 0.7493, 'learning_rate': 8.683978873239437e-05, 'epoch': 0.47}
{'loss': 0.7476, 'learning_rate': 8.679577464788732e-05, 'epoch': 0.47}
{'loss': 0.7318, 'learning_rate': 8.67517605633803e-05, 'epoch': 0.48}
{'loss': 0.7434, 'learning_rate': 8.670774647887324e-05, 'epoch': 0.48}
{'loss': 0.7516, 'learning_rate': 8.66637323943662e-05, 'epoch': 0.48}
{'loss': 0.7357, 'learning_rate': 8.661971830985915e-05, 'epoch': 0.48}
{'loss': 0.7286, 'learning_rate': 8.657570422535212e-05, 'epoch': 0.48}
{'loss': 0.6814, 'learning_rate': 8.653169014084508e-05, 'epoch': 0.48}
{'loss': 0.7218, 'learning_rate': 8.648767605633803e-05, 'epoch': 0.48}
{'loss': 0.7202, 'learning_rate': 8.644366197183099e-05, 'epoch': 0.49}
{'loss': 0.7394, 'learning_rate': 8.639964788732395e-05, 'epoch': 0.49}
{'loss': 0.7252, 'learning_rate': 8.63556338028169e-05, 'epoch': 0.49}
{'loss': 0.7284, 'learning_rate': 8.631161971830987e-05, 'epoch': 0.49}
{'loss': 0.7463, 'learning_rate': 8.626760563380281e-05, 'epoch': 0.49}
{'loss': 0.7129, 'learning_rate': 8.622359154929579e-05, 'epoch': 0.49}
{'loss': 0.7093, 'learning_rate': 8.617957746478874e-05, 'epoch': 0.49}
{'loss': 0.7189, 'learning_rate': 8.613556338028169e-05, 'epoch': 0.49}
{'loss': 0.6839, 'learning_rate': 8.609154929577465e-05, 'epoch': 0.5}
{'loss': 0.7552, 'learning_rate': 8.604753521126761e-05, 'epoch': 0.5}
{'loss': 0.7083, 'learning_rate': 8.600352112676057e-05, 'epoch': 0.5}
{'loss': 0.7198, 'learning_rate': 8.595950704225353e-05, 'epoch': 0.5}
{'loss': 0.768, 'learning_rate': 8.591549295774647e-05, 'epoch': 0.5}
{'loss': 0.7148, 'learning_rate': 8.587147887323945e-05, 'epoch': 0.5}
{'loss': 0.7176, 'learning_rate': 8.582746478873241e-05, 'epoch': 0.5}
{'loss': 0.7226, 'learning_rate': 8.578345070422535e-05, 'epoch': 0.5}
{'loss': 0.7165, 'learning_rate': 8.573943661971831e-05, 'epoch': 0.51}
{'loss': 0.7323, 'learning_rate': 8.569542253521127e-05, 'epoch': 0.51}
{'loss': 0.7238, 'learning_rate': 8.565140845070423e-05, 'epoch': 0.51}
{'loss': 0.6839, 'learning_rate': 8.560739436619719e-05, 'epoch': 0.51}
{'loss': 0.6823, 'learning_rate': 8.556338028169014e-05, 'epoch': 0.51}
{'loss': 0.7418, 'learning_rate': 8.551936619718311e-05, 'epoch': 0.51}
{'loss': 0.7099, 'learning_rate': 8.547535211267607e-05, 'epoch': 0.51}
{'loss': 0.6957, 'learning_rate': 8.543133802816902e-05, 'epoch': 0.51}
{'loss': 0.6944, 'learning_rate': 8.538732394366198e-05, 'epoch': 0.52}
{'loss': 0.7337, 'learning_rate': 8.534330985915494e-05, 'epoch': 0.52}
{'loss': 0.756, 'learning_rate': 8.52992957746479e-05, 'epoch': 0.52}
{'loss': 0.7418, 'learning_rate': 8.525528169014085e-05, 'epoch': 0.52}
{'loss': 0.7293, 'learning_rate': 8.52112676056338e-05, 'epoch': 0.52}
{'loss': 0.7334, 'learning_rate': 8.516725352112676e-05, 'epoch': 0.52}
{'loss': 0.7301, 'learning_rate': 8.512323943661972e-05, 'epoch': 0.52}
{'loss': 0.7108, 'learning_rate': 8.507922535211268e-05, 'epoch': 0.52}
{'loss': 0.7474, 'learning_rate': 8.503521126760564e-05, 'epoch': 0.53}
{'loss': 0.701, 'learning_rate': 8.49911971830986e-05, 'epoch': 0.53}
{'loss': 0.7134, 'learning_rate': 8.494718309859156e-05, 'epoch': 0.53}
{'loss': 0.7412, 'learning_rate': 8.490316901408452e-05, 'epoch': 0.53}
{'loss': 0.6809, 'learning_rate': 8.485915492957746e-05, 'epoch': 0.53}
{'loss': 0.6861, 'learning_rate': 8.481514084507042e-05, 'epoch': 0.53}
{'loss': 0.7329, 'learning_rate': 8.477112676056338e-05, 'epoch': 0.53}
{'loss': 0.6967, 'learning_rate': 8.472711267605634e-05, 'epoch': 0.54}
{'loss': 0.744, 'learning_rate': 8.46830985915493e-05, 'epoch': 0.54}
{'loss': 0.7189, 'learning_rate': 8.463908450704226e-05, 'epoch': 0.54}
{'loss': 0.714, 'learning_rate': 8.459507042253522e-05, 'epoch': 0.54}
{'loss': 0.7307, 'learning_rate': 8.455105633802818e-05, 'epoch': 0.54}
{'loss': 0.6956, 'learning_rate': 8.450704225352113e-05, 'epoch': 0.54}
{'loss': 0.7471, 'learning_rate': 8.446302816901409e-05, 'epoch': 0.54}
{'loss': 0.7204, 'learning_rate': 8.441901408450704e-05, 'epoch': 0.54}
{'loss': 0.7546, 'learning_rate': 8.4375e-05, 'epoch': 0.55}
{'loss': 0.7198, 'learning_rate': 8.433098591549296e-05, 'epoch': 0.55}
{'loss': 0.6902, 'learning_rate': 8.428697183098592e-05, 'epoch': 0.55}
{'loss': 0.6954, 'learning_rate': 8.424295774647888e-05, 'epoch': 0.55}
{'loss': 0.7008, 'learning_rate': 8.419894366197183e-05, 'epoch': 0.55}
{'loss': 0.703, 'learning_rate': 8.415492957746479e-05, 'epoch': 0.55}
{'loss': 0.7193, 'learning_rate': 8.411091549295775e-05, 'epoch': 0.55}
{'loss': 0.7339, 'learning_rate': 8.406690140845071e-05, 'epoch': 0.55}
{'loss': 0.7278, 'learning_rate': 8.402288732394367e-05, 'epoch': 0.56}
{'loss': 0.7423, 'learning_rate': 8.397887323943663e-05, 'epoch': 0.56}
{'loss': 0.7195, 'learning_rate': 8.393485915492957e-05, 'epoch': 0.56}
{'loss': 0.747, 'learning_rate': 8.389084507042255e-05, 'epoch': 0.56}
{'loss': 0.7256, 'learning_rate': 8.384683098591549e-05, 'epoch': 0.56}
{'loss': 0.7132, 'learning_rate': 8.380281690140845e-05, 'epoch': 0.56}
{'loss': 0.7209, 'learning_rate': 8.375880281690141e-05, 'epoch': 0.56}
{'loss': 0.7332, 'learning_rate': 8.371478873239437e-05, 'epoch': 0.56}
{'loss': 0.7204, 'learning_rate': 8.367077464788733e-05, 'epoch': 0.57}
{'loss': 0.7173, 'learning_rate': 8.362676056338029e-05, 'epoch': 0.57}
{'loss': 0.7241, 'learning_rate': 8.358274647887324e-05, 'epoch': 0.57}
{'loss': 0.7212, 'learning_rate': 8.353873239436621e-05, 'epoch': 0.57}
{'loss': 0.7555, 'learning_rate': 8.349471830985915e-05, 'epoch': 0.57}
{'loss': 0.7071, 'learning_rate': 8.345070422535211e-05, 'epoch': 0.57}
{'loss': 0.7053, 'learning_rate': 8.340669014084507e-05, 'epoch': 0.57}
{'loss': 0.7118, 'learning_rate': 8.336267605633803e-05, 'epoch': 0.57}
{'loss': 0.7038, 'learning_rate': 8.331866197183099e-05, 'epoch': 0.58}
{'loss': 0.7145, 'learning_rate': 8.327464788732394e-05, 'epoch': 0.58}
{'loss': 0.7245, 'learning_rate': 8.32306338028169e-05, 'epoch': 0.58}
{'loss': 0.7235, 'learning_rate': 8.318661971830987e-05, 'epoch': 0.58}
{'loss': 0.7149, 'learning_rate': 8.314260563380282e-05, 'epoch': 0.58}
{'loss': 0.7349, 'learning_rate': 8.309859154929578e-05, 'epoch': 0.58}
{'loss': 0.6916, 'learning_rate': 8.305457746478874e-05, 'epoch': 0.58}
{'loss': 0.7242, 'learning_rate': 8.30105633802817e-05, 'epoch': 0.58}
{'loss': 0.7064, 'learning_rate': 8.296654929577466e-05, 'epoch': 0.59}
{'loss': 0.709, 'learning_rate': 8.29225352112676e-05, 'epoch': 0.59}
{'loss': 0.7046, 'learning_rate': 8.287852112676056e-05, 'epoch': 0.59}
{'loss': 0.7038, 'learning_rate': 8.283450704225353e-05, 'epoch': 0.59}
{'loss': 0.7044, 'learning_rate': 8.279049295774648e-05, 'epoch': 0.59}
{'loss': 0.7502, 'learning_rate': 8.274647887323944e-05, 'epoch': 0.59}
{'loss': 0.7198, 'learning_rate': 8.27024647887324e-05, 'epoch': 0.59}
{'loss': 0.74, 'learning_rate': 8.265845070422536e-05, 'epoch': 0.6}
{'loss': 0.7086, 'learning_rate': 8.261443661971832e-05, 'epoch': 0.6}
{'loss': 0.7218, 'learning_rate': 8.257042253521126e-05, 'epoch': 0.6}
{'loss': 0.6996, 'learning_rate': 8.252640845070422e-05, 'epoch': 0.6}
{'loss': 0.7062, 'learning_rate': 8.24823943661972e-05, 'epoch': 0.6}
{'loss': 0.6849, 'learning_rate': 8.243838028169014e-05, 'epoch': 0.6}
{'loss': 0.7029, 'learning_rate': 8.23943661971831e-05, 'epoch': 0.6}
{'loss': 0.7115, 'learning_rate': 8.235035211267606e-05, 'epoch': 0.6}
{'loss': 0.6828, 'learning_rate': 8.230633802816902e-05, 'epoch': 0.61}
{'loss': 0.6976, 'learning_rate': 8.226232394366198e-05, 'epoch': 0.61}
{'loss': 0.6938, 'learning_rate': 8.221830985915493e-05, 'epoch': 0.61}
{'loss': 0.7238, 'learning_rate': 8.217429577464789e-05, 'epoch': 0.61}
{'loss': 0.7374, 'learning_rate': 8.213028169014086e-05, 'epoch': 0.61}
{'loss': 0.7366, 'learning_rate': 8.20862676056338e-05, 'epoch': 0.61}
{'loss': 0.7484, 'learning_rate': 8.204225352112677e-05, 'epoch': 0.61}
{'loss': 0.7171, 'learning_rate': 8.199823943661971e-05, 'epoch': 0.61}
{'loss': 0.7322, 'learning_rate': 8.195422535211268e-05, 'epoch': 0.62}
{'loss': 0.6649, 'learning_rate': 8.191021126760564e-05, 'epoch': 0.62}
{'loss': 0.7107, 'learning_rate': 8.186619718309859e-05, 'epoch': 0.62}
{'loss': 0.7124, 'learning_rate': 8.182218309859155e-05, 'epoch': 0.62}
{'loss': 0.7048, 'learning_rate': 8.177816901408452e-05, 'epoch': 0.62}
{'loss': 0.6972, 'learning_rate': 8.173415492957747e-05, 'epoch': 0.62}
{'loss': 0.7237, 'learning_rate': 8.169014084507043e-05, 'epoch': 0.62}
{'loss': 0.7223, 'learning_rate': 8.164612676056337e-05, 'epoch': 0.62}
{'loss': 0.7492, 'learning_rate': 8.160211267605635e-05, 'epoch': 0.63}
{'loss': 0.7011, 'learning_rate': 8.15580985915493e-05, 'epoch': 0.63}
{'loss': 0.7211, 'learning_rate': 8.151408450704225e-05, 'epoch': 0.63}
{'loss': 0.6603, 'learning_rate': 8.147007042253521e-05, 'epoch': 0.63}
{'loss': 0.7076, 'learning_rate': 8.142605633802817e-05, 'epoch': 0.63}
{'loss': 0.7227, 'learning_rate': 8.138204225352113e-05, 'epoch': 0.63}
{'loss': 0.7073, 'learning_rate': 8.133802816901409e-05, 'epoch': 0.63}
{'loss': 0.7019, 'learning_rate': 8.129401408450704e-05, 'epoch': 0.63}
{'loss': 0.6913, 'learning_rate': 8.125000000000001e-05, 'epoch': 0.64}
{'loss': 0.6953, 'learning_rate': 8.120598591549297e-05, 'epoch': 0.64}
{'loss': 0.7032, 'learning_rate': 8.116197183098592e-05, 'epoch': 0.64}
{'loss': 0.7341, 'learning_rate': 8.111795774647887e-05, 'epoch': 0.64}
{'loss': 0.7146, 'learning_rate': 8.107394366197183e-05, 'epoch': 0.64}
{'loss': 0.6792, 'learning_rate': 8.10299295774648e-05, 'epoch': 0.64}
{'loss': 0.7217, 'learning_rate': 8.098591549295775e-05, 'epoch': 0.64}
{'loss': 0.7097, 'learning_rate': 8.09419014084507e-05, 'epoch': 0.65}
{'loss': 0.724, 'learning_rate': 8.089788732394367e-05, 'epoch': 0.65}
{'loss': 0.7116, 'learning_rate': 8.085387323943663e-05, 'epoch': 0.65}
{'loss': 0.7533, 'learning_rate': 8.080985915492958e-05, 'epoch': 0.65}
{'loss': 0.688, 'learning_rate': 8.076584507042254e-05, 'epoch': 0.65}
{'loss': 0.6808, 'learning_rate': 8.07218309859155e-05, 'epoch': 0.65}
{'loss': 0.7018, 'learning_rate': 8.067781690140846e-05, 'epoch': 0.65}
{'loss': 0.7477, 'learning_rate': 8.063380281690142e-05, 'epoch': 0.65}
{'loss': 0.6996, 'learning_rate': 8.058978873239436e-05, 'epoch': 0.66}
{'loss': 0.6811, 'learning_rate': 8.054577464788734e-05, 'epoch': 0.66}
{'loss': 0.7294, 'learning_rate': 8.05017605633803e-05, 'epoch': 0.66}
{'loss': 0.7151, 'learning_rate': 8.045774647887324e-05, 'epoch': 0.66}
{'loss': 0.6725, 'learning_rate': 8.04137323943662e-05, 'epoch': 0.66}
{'loss': 0.7138, 'learning_rate': 8.036971830985916e-05, 'epoch': 0.66}
{'loss': 0.7129, 'learning_rate': 8.032570422535212e-05, 'epoch': 0.66}
{'loss': 0.7488, 'learning_rate': 8.028169014084508e-05, 'epoch': 0.66}
{'loss': 0.7188, 'learning_rate': 8.023767605633803e-05, 'epoch': 0.67}
{'loss': 0.7189, 'learning_rate': 8.019366197183098e-05, 'epoch': 0.67}
{'loss': 0.7106, 'learning_rate': 8.014964788732394e-05, 'epoch': 0.67}
{'eval_loss': 0.8858120441436768, 'eval_runtime': 190.9361, 'eval_samples_per_second': 52.342, 'eval_steps_per_second': 1.639, 'epoch': 0.67}
{'loss': 0.7057, 'learning_rate': 8.01056338028169e-05, 'epoch': 0.67}
{'loss': 0.7747, 'learning_rate': 8.006161971830986e-05, 'epoch': 0.67}
{'loss': 0.6956, 'learning_rate': 8.001760563380282e-05, 'epoch': 0.67}
{'loss': 0.7574, 'learning_rate': 7.997359154929578e-05, 'epoch': 0.67}
{'loss': 0.7411, 'learning_rate': 7.992957746478874e-05, 'epoch': 0.67}
{'loss': 0.714, 'learning_rate': 7.988556338028169e-05, 'epoch': 0.68}
{'loss': 0.7065, 'learning_rate': 7.984154929577465e-05, 'epoch': 0.68}
{'loss': 0.7134, 'learning_rate': 7.979753521126761e-05, 'epoch': 0.68}
{'loss': 0.7139, 'learning_rate': 7.975352112676057e-05, 'epoch': 0.68}
{'loss': 0.7014, 'learning_rate': 7.970950704225353e-05, 'epoch': 0.68}
{'loss': 0.6736, 'learning_rate': 7.966549295774649e-05, 'epoch': 0.68}
{'loss': 0.7051, 'learning_rate': 7.962147887323945e-05, 'epoch': 0.68}
{'loss': 0.7028, 'learning_rate': 7.95774647887324e-05, 'epoch': 0.68}
{'loss': 0.6906, 'learning_rate': 7.953345070422535e-05, 'epoch': 0.69}
{'loss': 0.7048, 'learning_rate': 7.948943661971831e-05, 'epoch': 0.69}
{'loss': 0.7252, 'learning_rate': 7.944542253521127e-05, 'epoch': 0.69}
{'loss': 0.6958, 'learning_rate': 7.940140845070423e-05, 'epoch': 0.69}
{'loss': 0.7116, 'learning_rate': 7.935739436619719e-05, 'epoch': 0.69}
{'loss': 0.7185, 'learning_rate': 7.931338028169015e-05, 'epoch': 0.69}
{'loss': 0.733, 'learning_rate': 7.926936619718311e-05, 'epoch': 0.69}
{'loss': 0.701, 'learning_rate': 7.922535211267607e-05, 'epoch': 0.7}
{'loss': 0.7272, 'learning_rate': 7.918133802816901e-05, 'epoch': 0.7}
{'loss': 0.682, 'learning_rate': 7.913732394366197e-05, 'epoch': 0.7}
{'loss': 0.6869, 'learning_rate': 7.909330985915493e-05, 'epoch': 0.7}
{'loss': 0.7376, 'learning_rate': 7.904929577464789e-05, 'epoch': 0.7}
{'loss': 0.7046, 'learning_rate': 7.900528169014085e-05, 'epoch': 0.7}
