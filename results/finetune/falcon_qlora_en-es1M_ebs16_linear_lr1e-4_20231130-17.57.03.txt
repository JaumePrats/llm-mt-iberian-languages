====================================================================================================
FINETUNING PARAMETERS:
base model: tiiuae/falcon-7b
--------------------------------------------------
train_split: [:2000000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/falcon_qlora_en-es1M_ebs16_linear_lr1e-4_20231130-17.57.03
--------------------------------------------------
learning_rate: 0.0001
lr_scheduler_type: linear
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
max_steps: 10000
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 50
--------------------------------------------------
lora_r: 16
lora_alpha: 16
--------------------------------------------------
bf16: True
--------------------------------------------------
use_4bit: True
bnb_4bit_quant_type: nf4
bnb_4bit_compute_dtype: float16
====================================================================================================
================================================================================
Your GPU supports bfloat16, you can accelerate training with the argument --bf16
================================================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 2000000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 2000000
})
False
False
{'loss': 1.0387, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.0}
{'loss': 0.9667, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.0}
{'loss': 1.0017, 'learning_rate': 1e-05, 'epoch': 0.0}
{'loss': 0.9759, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.0}
{'loss': 0.9207, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.0}
{'eval_loss': 0.8145907521247864, 'eval_runtime': 723.4382, 'eval_samples_per_second': 13.815, 'eval_steps_per_second': 1.728, 'epoch': 0.0}
{'loss': 0.8339, 'learning_rate': 2e-05, 'epoch': 0.0}
{'loss': 0.7972, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.0}
{'loss': 0.8477, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7891, 'learning_rate': 3e-05, 'epoch': 0.0}
{'loss': 0.8328, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.0}
{'eval_loss': 0.7469950914382935, 'eval_runtime': 714.7689, 'eval_samples_per_second': 13.982, 'eval_steps_per_second': 1.749, 'epoch': 0.0}
{'loss': 0.7791, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.0}
{'loss': 0.7613, 'learning_rate': 4e-05, 'epoch': 0.0}
{'loss': 0.7619, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.0}
{'loss': 0.7868, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7439, 'learning_rate': 5e-05, 'epoch': 0.0}
{'eval_loss': 0.7314556837081909, 'eval_runtime': 726.574, 'eval_samples_per_second': 13.755, 'eval_steps_per_second': 1.72, 'epoch': 0.0}
{'loss': 0.7642, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.0}
{'loss': 0.7982, 'learning_rate': 5.666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7261, 'learning_rate': 6e-05, 'epoch': 0.0}
{'loss': 0.7631, 'learning_rate': 6.333333333333333e-05, 'epoch': 0.0}
{'loss': 0.7842, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.0}
{'eval_loss': 0.7172340750694275, 'eval_runtime': 737.0675, 'eval_samples_per_second': 13.559, 'eval_steps_per_second': 1.696, 'epoch': 0.0}
{'loss': 0.7124, 'learning_rate': 7e-05, 'epoch': 0.0}
{'loss': 0.7299, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.0}
{'loss': 0.7314, 'learning_rate': 7.666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7907, 'learning_rate': 8e-05, 'epoch': 0.0}
{'loss': 0.7485, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.0}
{'eval_loss': 0.711211621761322, 'eval_runtime': 748.1817, 'eval_samples_per_second': 13.358, 'eval_steps_per_second': 1.671, 'epoch': 0.0}
{'loss': 0.7542, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7674, 'learning_rate': 9e-05, 'epoch': 0.0}
{'loss': 0.7248, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.0}
{'loss': 0.743, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.0}
{'loss': 0.7605, 'learning_rate': 0.0001, 'epoch': 0.0}
