==================================================
FINETUNING PARAMETERS:
base model: tiiuae/falcon-7b
--------------------------------------------------
train_split: [:20000]
dataset_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/en-es_europarl-unpc/europarl-unpc_en-es_bidir.jsonl
validation_files:
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_eng-spa.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/flores_dev_spa-eng.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_en-es_unidir.jsonl
	/fs/surtr0/jprats/data/processed/04-finetuning/devsets/unpc_dev_es-en_unidir.jsonl
--------------------------------------------------
output_dir: /fs/surtr0/jprats/models/checkpoints/falcon_fft_en-es10k_ebs16_linear_lr1e-5_20231204-18.04.15
--------------------------------------------------
learning_rate: 1e-05
lr_scheduler_type: linear
per_device_train_batch_size: 4
gradient_accumulation_steps: 4
max_steps: 10000
warmup_ratio: 0.03
group_by_length: False
evaluation_strategy: steps
eval_steps: 50
--------------------------------------------------
bf16: True
==================================================
Resulting dataset:
Dataset({
    features: ['text'],
    num_rows: 20000
})
Resulting validation dataset:
Dataset({
    features: ['text'],
    num_rows: 9994
})
Dataset({
    features: ['text'],
    num_rows: 20000
})
False
False
Grad req: transformer.word_embeddings.weight
Grad req: transformer.h.0.self_attention.query_key_value.weight
Grad req: transformer.h.0.self_attention.dense.weight
Grad req: transformer.h.0.mlp.dense_h_to_4h.weight
Grad req: transformer.h.0.mlp.dense_4h_to_h.weight
Grad req: transformer.h.0.input_layernorm.weight
Grad req: transformer.h.0.input_layernorm.bias
Grad req: transformer.h.1.self_attention.query_key_value.weight
Grad req: transformer.h.1.self_attention.dense.weight
Grad req: transformer.h.1.mlp.dense_h_to_4h.weight
Grad req: transformer.h.1.mlp.dense_4h_to_h.weight
Grad req: transformer.h.1.input_layernorm.weight
Grad req: transformer.h.1.input_layernorm.bias
Grad req: transformer.h.2.self_attention.query_key_value.weight
Grad req: transformer.h.2.self_attention.dense.weight
Grad req: transformer.h.2.mlp.dense_h_to_4h.weight
Grad req: transformer.h.2.mlp.dense_4h_to_h.weight
Grad req: transformer.h.2.input_layernorm.weight
Grad req: transformer.h.2.input_layernorm.bias
Grad req: transformer.h.3.self_attention.query_key_value.weight
Grad req: transformer.h.3.self_attention.dense.weight
Grad req: transformer.h.3.mlp.dense_h_to_4h.weight
Grad req: transformer.h.3.mlp.dense_4h_to_h.weight
Grad req: transformer.h.3.input_layernorm.weight
Grad req: transformer.h.3.input_layernorm.bias
Grad req: transformer.h.4.self_attention.query_key_value.weight
Grad req: transformer.h.4.self_attention.dense.weight
Grad req: transformer.h.4.mlp.dense_h_to_4h.weight
Grad req: transformer.h.4.mlp.dense_4h_to_h.weight
Grad req: transformer.h.4.input_layernorm.weight
Grad req: transformer.h.4.input_layernorm.bias
Grad req: transformer.h.5.self_attention.query_key_value.weight
Grad req: transformer.h.5.self_attention.dense.weight
Grad req: transformer.h.5.mlp.dense_h_to_4h.weight
Grad req: transformer.h.5.mlp.dense_4h_to_h.weight
Grad req: transformer.h.5.input_layernorm.weight
Grad req: transformer.h.5.input_layernorm.bias
Grad req: transformer.h.6.self_attention.query_key_value.weight
Grad req: transformer.h.6.self_attention.dense.weight
Grad req: transformer.h.6.mlp.dense_h_to_4h.weight
Grad req: transformer.h.6.mlp.dense_4h_to_h.weight
Grad req: transformer.h.6.input_layernorm.weight
Grad req: transformer.h.6.input_layernorm.bias
Grad req: transformer.h.7.self_attention.query_key_value.weight
Grad req: transformer.h.7.self_attention.dense.weight
Grad req: transformer.h.7.mlp.dense_h_to_4h.weight
Grad req: transformer.h.7.mlp.dense_4h_to_h.weight
Grad req: transformer.h.7.input_layernorm.weight
Grad req: transformer.h.7.input_layernorm.bias
Grad req: transformer.h.8.self_attention.query_key_value.weight
Grad req: transformer.h.8.self_attention.dense.weight
Grad req: transformer.h.8.mlp.dense_h_to_4h.weight
Grad req: transformer.h.8.mlp.dense_4h_to_h.weight
Grad req: transformer.h.8.input_layernorm.weight
Grad req: transformer.h.8.input_layernorm.bias
Grad req: transformer.h.9.self_attention.query_key_value.weight
Grad req: transformer.h.9.self_attention.dense.weight
Grad req: transformer.h.9.mlp.dense_h_to_4h.weight
Grad req: transformer.h.9.mlp.dense_4h_to_h.weight
Grad req: transformer.h.9.input_layernorm.weight
Grad req: transformer.h.9.input_layernorm.bias
Grad req: transformer.h.10.self_attention.query_key_value.weight
Grad req: transformer.h.10.self_attention.dense.weight
Grad req: transformer.h.10.mlp.dense_h_to_4h.weight
Grad req: transformer.h.10.mlp.dense_4h_to_h.weight
Grad req: transformer.h.10.input_layernorm.weight
Grad req: transformer.h.10.input_layernorm.bias
Grad req: transformer.h.11.self_attention.query_key_value.weight
Grad req: transformer.h.11.self_attention.dense.weight
Grad req: transformer.h.11.mlp.dense_h_to_4h.weight
Grad req: transformer.h.11.mlp.dense_4h_to_h.weight
Grad req: transformer.h.11.input_layernorm.weight
Grad req: transformer.h.11.input_layernorm.bias
Grad req: transformer.h.12.self_attention.query_key_value.weight
Grad req: transformer.h.12.self_attention.dense.weight
Grad req: transformer.h.12.mlp.dense_h_to_4h.weight
Grad req: transformer.h.12.mlp.dense_4h_to_h.weight
Grad req: transformer.h.12.input_layernorm.weight
Grad req: transformer.h.12.input_layernorm.bias
Grad req: transformer.h.13.self_attention.query_key_value.weight
Grad req: transformer.h.13.self_attention.dense.weight
Grad req: transformer.h.13.mlp.dense_h_to_4h.weight
Grad req: transformer.h.13.mlp.dense_4h_to_h.weight
Grad req: transformer.h.13.input_layernorm.weight
Grad req: transformer.h.13.input_layernorm.bias
Grad req: transformer.h.14.self_attention.query_key_value.weight
Grad req: transformer.h.14.self_attention.dense.weight
Grad req: transformer.h.14.mlp.dense_h_to_4h.weight
Grad req: transformer.h.14.mlp.dense_4h_to_h.weight
Grad req: transformer.h.14.input_layernorm.weight
Grad req: transformer.h.14.input_layernorm.bias
Grad req: transformer.h.15.self_attention.query_key_value.weight
Grad req: transformer.h.15.self_attention.dense.weight
Grad req: transformer.h.15.mlp.dense_h_to_4h.weight
Grad req: transformer.h.15.mlp.dense_4h_to_h.weight
Grad req: transformer.h.15.input_layernorm.weight
Grad req: transformer.h.15.input_layernorm.bias
Grad req: transformer.h.16.self_attention.query_key_value.weight
Grad req: transformer.h.16.self_attention.dense.weight
Grad req: transformer.h.16.mlp.dense_h_to_4h.weight
Grad req: transformer.h.16.mlp.dense_4h_to_h.weight
Grad req: transformer.h.16.input_layernorm.weight
Grad req: transformer.h.16.input_layernorm.bias
Grad req: transformer.h.17.self_attention.query_key_value.weight
Grad req: transformer.h.17.self_attention.dense.weight
Grad req: transformer.h.17.mlp.dense_h_to_4h.weight
Grad req: transformer.h.17.mlp.dense_4h_to_h.weight
Grad req: transformer.h.17.input_layernorm.weight
Grad req: transformer.h.17.input_layernorm.bias
Grad req: transformer.h.18.self_attention.query_key_value.weight
Grad req: transformer.h.18.self_attention.dense.weight
Grad req: transformer.h.18.mlp.dense_h_to_4h.weight
Grad req: transformer.h.18.mlp.dense_4h_to_h.weight
Grad req: transformer.h.18.input_layernorm.weight
Grad req: transformer.h.18.input_layernorm.bias
Grad req: transformer.h.19.self_attention.query_key_value.weight
Grad req: transformer.h.19.self_attention.dense.weight
Grad req: transformer.h.19.mlp.dense_h_to_4h.weight
Grad req: transformer.h.19.mlp.dense_4h_to_h.weight
Grad req: transformer.h.19.input_layernorm.weight
Grad req: transformer.h.19.input_layernorm.bias
Grad req: transformer.h.20.self_attention.query_key_value.weight
Grad req: transformer.h.20.self_attention.dense.weight
Grad req: transformer.h.20.mlp.dense_h_to_4h.weight
Grad req: transformer.h.20.mlp.dense_4h_to_h.weight
Grad req: transformer.h.20.input_layernorm.weight
Grad req: transformer.h.20.input_layernorm.bias
Grad req: transformer.h.21.self_attention.query_key_value.weight
Grad req: transformer.h.21.self_attention.dense.weight
Grad req: transformer.h.21.mlp.dense_h_to_4h.weight
Grad req: transformer.h.21.mlp.dense_4h_to_h.weight
Grad req: transformer.h.21.input_layernorm.weight
Grad req: transformer.h.21.input_layernorm.bias
Grad req: transformer.h.22.self_attention.query_key_value.weight
Grad req: transformer.h.22.self_attention.dense.weight
Grad req: transformer.h.22.mlp.dense_h_to_4h.weight
Grad req: transformer.h.22.mlp.dense_4h_to_h.weight
Grad req: transformer.h.22.input_layernorm.weight
Grad req: transformer.h.22.input_layernorm.bias
Grad req: transformer.h.23.self_attention.query_key_value.weight
Grad req: transformer.h.23.self_attention.dense.weight
Grad req: transformer.h.23.mlp.dense_h_to_4h.weight
Grad req: transformer.h.23.mlp.dense_4h_to_h.weight
Grad req: transformer.h.23.input_layernorm.weight
Grad req: transformer.h.23.input_layernorm.bias
Grad req: transformer.h.24.self_attention.query_key_value.weight
Grad req: transformer.h.24.self_attention.dense.weight
Grad req: transformer.h.24.mlp.dense_h_to_4h.weight
Grad req: transformer.h.24.mlp.dense_4h_to_h.weight
Grad req: transformer.h.24.input_layernorm.weight
Grad req: transformer.h.24.input_layernorm.bias
Grad req: transformer.h.25.self_attention.query_key_value.weight
Grad req: transformer.h.25.self_attention.dense.weight
Grad req: transformer.h.25.mlp.dense_h_to_4h.weight
Grad req: transformer.h.25.mlp.dense_4h_to_h.weight
Grad req: transformer.h.25.input_layernorm.weight
Grad req: transformer.h.25.input_layernorm.bias
Grad req: transformer.h.26.self_attention.query_key_value.weight
Grad req: transformer.h.26.self_attention.dense.weight
Grad req: transformer.h.26.mlp.dense_h_to_4h.weight
Grad req: transformer.h.26.mlp.dense_4h_to_h.weight
Grad req: transformer.h.26.input_layernorm.weight
Grad req: transformer.h.26.input_layernorm.bias
Grad req: transformer.h.27.self_attention.query_key_value.weight
Grad req: transformer.h.27.self_attention.dense.weight
Grad req: transformer.h.27.mlp.dense_h_to_4h.weight
Grad req: transformer.h.27.mlp.dense_4h_to_h.weight
Grad req: transformer.h.27.input_layernorm.weight
Grad req: transformer.h.27.input_layernorm.bias
Grad req: transformer.h.28.self_attention.query_key_value.weight
Grad req: transformer.h.28.self_attention.dense.weight
Grad req: transformer.h.28.mlp.dense_h_to_4h.weight
Grad req: transformer.h.28.mlp.dense_4h_to_h.weight
Grad req: transformer.h.28.input_layernorm.weight
Grad req: transformer.h.28.input_layernorm.bias
Grad req: transformer.h.29.self_attention.query_key_value.weight
Grad req: transformer.h.29.self_attention.dense.weight
Grad req: transformer.h.29.mlp.dense_h_to_4h.weight
Grad req: transformer.h.29.mlp.dense_4h_to_h.weight
Grad req: transformer.h.29.input_layernorm.weight
Grad req: transformer.h.29.input_layernorm.bias
Grad req: transformer.h.30.self_attention.query_key_value.weight
Grad req: transformer.h.30.self_attention.dense.weight
Grad req: transformer.h.30.mlp.dense_h_to_4h.weight
Grad req: transformer.h.30.mlp.dense_4h_to_h.weight
Grad req: transformer.h.30.input_layernorm.weight
Grad req: transformer.h.30.input_layernorm.bias
Grad req: transformer.h.31.self_attention.query_key_value.weight
Grad req: transformer.h.31.self_attention.dense.weight
Grad req: transformer.h.31.mlp.dense_h_to_4h.weight
Grad req: transformer.h.31.mlp.dense_4h_to_h.weight
Grad req: transformer.h.31.input_layernorm.weight
Grad req: transformer.h.31.input_layernorm.bias
Grad req: transformer.ln_f.weight
Grad req: transformer.ln_f.bias
{'loss': 1.0236, 'learning_rate': 3.3333333333333335e-07, 'epoch': 0.01}
{'loss': 0.9714, 'learning_rate': 6.666666666666667e-07, 'epoch': 0.02}
{'loss': 0.9806, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}
{'loss': 1.0164, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.03}
{'loss': 0.9477, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.04}
{'eval_loss': 0.8978729844093323, 'eval_runtime': 451.115, 'eval_samples_per_second': 22.154, 'eval_steps_per_second': 2.771, 'epoch': 0.04}
{'loss': 0.9614, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}
{'loss': 0.8877, 'learning_rate': 2.3333333333333336e-06, 'epoch': 0.06}
{'loss': 0.8738, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.06}
{'loss': 0.8144, 'learning_rate': 3e-06, 'epoch': 0.07}
{'loss': 0.8094, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.08}
{'eval_loss': 0.7584103941917419, 'eval_runtime': 442.5215, 'eval_samples_per_second': 22.584, 'eval_steps_per_second': 2.825, 'epoch': 0.08}
{'loss': 0.7925, 'learning_rate': 3.6666666666666666e-06, 'epoch': 0.09}
{'loss': 0.8103, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}
{'loss': 0.8058, 'learning_rate': 4.333333333333334e-06, 'epoch': 0.1}
{'loss': 0.7796, 'learning_rate': 4.666666666666667e-06, 'epoch': 0.11}
{'loss': 0.7858, 'learning_rate': 5e-06, 'epoch': 0.12}
{'eval_loss': 0.7380661368370056, 'eval_runtime': 444.1655, 'eval_samples_per_second': 22.501, 'eval_steps_per_second': 2.814, 'epoch': 0.12}
{'loss': 0.7997, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.13}
{'loss': 0.7396, 'learning_rate': 5.666666666666667e-06, 'epoch': 0.14}
{'loss': 0.7435, 'learning_rate': 6e-06, 'epoch': 0.14}
{'loss': 0.7952, 'learning_rate': 6.333333333333333e-06, 'epoch': 0.15}
{'loss': 0.7602, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.16}
{'eval_loss': 0.7233622670173645, 'eval_runtime': 440.1185, 'eval_samples_per_second': 22.708, 'eval_steps_per_second': 2.84, 'epoch': 0.16}
{'loss': 0.7363, 'learning_rate': 7e-06, 'epoch': 0.17}
{'loss': 0.7815, 'learning_rate': 7.333333333333333e-06, 'epoch': 0.18}
{'loss': 0.7623, 'learning_rate': 7.666666666666667e-06, 'epoch': 0.18}
{'loss': 0.7737, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.19}
{'loss': 0.7553, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.2}
{'eval_loss': 0.7095592617988586, 'eval_runtime': 442.0948, 'eval_samples_per_second': 22.606, 'eval_steps_per_second': 2.827, 'epoch': 0.2}
{'loss': 0.7604, 'learning_rate': 8.666666666666668e-06, 'epoch': 0.21}
{'loss': 0.719, 'learning_rate': 9e-06, 'epoch': 0.22}
{'loss': 0.7697, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.22}
{'loss': 0.7027, 'learning_rate': 9.666666666666667e-06, 'epoch': 0.23}
{'loss': 0.7346, 'learning_rate': 1e-05, 'epoch': 0.24}
{'eval_loss': 0.7011261582374573, 'eval_runtime': 438.9352, 'eval_samples_per_second': 22.769, 'eval_steps_per_second': 2.848, 'epoch': 0.24}
{'loss': 0.687, 'learning_rate': 9.989690721649485e-06, 'epoch': 0.25}
{'loss': 0.7371, 'learning_rate': 9.97938144329897e-06, 'epoch': 0.26}
{'loss': 0.7152, 'learning_rate': 9.969072164948454e-06, 'epoch': 0.26}
{'loss': 0.7507, 'learning_rate': 9.958762886597939e-06, 'epoch': 0.27}
{'loss': 0.7414, 'learning_rate': 9.948453608247423e-06, 'epoch': 0.28}
{'eval_loss': 0.6943101286888123, 'eval_runtime': 453.6768, 'eval_samples_per_second': 22.029, 'eval_steps_per_second': 2.755, 'epoch': 0.28}
{'loss': 0.7468, 'learning_rate': 9.938144329896908e-06, 'epoch': 0.29}
{'loss': 0.7184, 'learning_rate': 9.927835051546392e-06, 'epoch': 0.3}
{'loss': 0.7431, 'learning_rate': 9.917525773195877e-06, 'epoch': 0.3}
{'loss': 0.7351, 'learning_rate': 9.907216494845361e-06, 'epoch': 0.31}
{'loss': 0.6975, 'learning_rate': 9.896907216494846e-06, 'epoch': 0.32}
{'eval_loss': 0.6874960660934448, 'eval_runtime': 444.6459, 'eval_samples_per_second': 22.476, 'eval_steps_per_second': 2.811, 'epoch': 0.32}
{'loss': 0.7447, 'learning_rate': 9.88659793814433e-06, 'epoch': 0.33}
{'loss': 0.7269, 'learning_rate': 9.876288659793815e-06, 'epoch': 0.34}
{'loss': 0.6845, 'learning_rate': 9.8659793814433e-06, 'epoch': 0.34}
{'loss': 0.7243, 'learning_rate': 9.855670103092784e-06, 'epoch': 0.35}
{'loss': 0.7314, 'learning_rate': 9.84536082474227e-06, 'epoch': 0.36}
{'eval_loss': 0.6819783449172974, 'eval_runtime': 442.5029, 'eval_samples_per_second': 22.585, 'eval_steps_per_second': 2.825, 'epoch': 0.36}
{'loss': 0.7202, 'learning_rate': 9.835051546391753e-06, 'epoch': 0.37}
{'loss': 0.725, 'learning_rate': 9.824742268041238e-06, 'epoch': 0.38}
{'loss': 0.7034, 'learning_rate': 9.814432989690722e-06, 'epoch': 0.38}
{'loss': 0.6785, 'learning_rate': 9.804123711340207e-06, 'epoch': 0.39}
{'loss': 0.6902, 'learning_rate': 9.793814432989691e-06, 'epoch': 0.4}
{'eval_loss': 0.6793445944786072, 'eval_runtime': 441.2921, 'eval_samples_per_second': 22.647, 'eval_steps_per_second': 2.833, 'epoch': 0.4}
{'loss': 0.7475, 'learning_rate': 9.783505154639176e-06, 'epoch': 0.41}
{'loss': 0.6876, 'learning_rate': 9.77319587628866e-06, 'epoch': 0.42}
{'loss': 0.6921, 'learning_rate': 9.762886597938145e-06, 'epoch': 0.42}
{'loss': 0.7172, 'learning_rate': 9.752577319587629e-06, 'epoch': 0.43}
{'loss': 0.7089, 'learning_rate': 9.742268041237114e-06, 'epoch': 0.44}
